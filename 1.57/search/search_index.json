{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Open Data Manager Documentation","text":"<p>This documentation contains information how to use ODM system.</p>"},{"location":"deployment/clouds/aws/","title":"Amazon Web Services (AWS)","text":""},{"location":"deployment/clouds/aws/#required-types-of-resources","title":"Required types of resources","text":"<ul> <li>AWS S3 Bucket</li> <li>AWS IAM user with bucket access above (programmatic access)</li> <li>AWS EKS<ul> <li>AWS EBS</li> <li>AWS ALB</li> <li>AWS ACM</li> <li>AWS Route53</li> </ul> </li> </ul>"},{"location":"deployment/clouds/aws/#steps-for-creating-aws-resources","title":"Steps for creating AWS resources","text":"<ol> <li> <p>Create S3 Bucket.</p> <ul> <li> <p>You can use the S3 Bucket only from one region, it is recommended to use a common region with EKS.</p> </li> <li> <p>The S3 Bucket can use KMS or default S3 encryption.</p> </li> <li> <p>You need to configure CORS, you can find an example here CORS configuration for S3</p> </li> </ul> </li> <li> <p>Create IAM user, policy (it will be listed below) and attach the policy to the user.</p> <ul> <li> <p>Programmatic access is required to work ODM with IAM user.</p> </li> <li> <p>You can find the recommended IAM policy here IAM policy for S3 access.</p> </li> </ul> </li> <li> <p>Create VPC.</p> <ul> <li> <p>Must have at least 2 private subnets [link].</p> </li> <li> <p>Each subnets must contain at least 100 free IP addresses [recommendation].</p> </li> </ul> </li> <li> <p>Create EKS.</p> <ul> <li>Deploy the addons you need.</li> </ul> </li> <li> <p>Create Route53 hosted zone.</p> <ul> <li> <p>You can use private or public zone.</p> </li> <li> <p>It is recommended to use <code>A</code> type of record and a simple routing method.</p> </li> <li> <p>The recording name should refer to your service (for example ALB).</p> </li> </ul> </li> <li> <p>Create ACM with your FQDN.</p> <ul> <li>You can use wildcard certificate.</li> </ul> </li> <li> <p>Create ALB with ACM above.</p> <ul> <li> <p>If you do not have strict security requirements for ALB, then it is better to use the automatic creation of ALB using the ALB controller (details below in EKS configuration).</p> </li> <li> <p>You can use either internal or public schema depending on your situation (with an internal scheme, SCIM synchronization with Azure AD will not work, only SSO Authorization).</p> </li> <li> <p>ALB Configuration</p> <ul> <li> <p>HTTP/2 - <code>On</code></p> </li> <li> <p>Idle timeout - <code>4000 seconds</code></p> </li> </ul> </li> </ul> </li> </ol>"},{"location":"deployment/clouds/aws/#recommended-steps-for-eks-configuration","title":"Recommended steps for EKS configuration","text":"<ol> <li> <p>Deploy EBS controller.</p> <ul> <li> <p>Following the documentation, it is required to create an IAM role and deploy the EKS addon.</p> </li> <li> <p>It is recommended to use GP3 storages (to do this, you need to deploy a specific StorageClass, example), but if required, you can use the default GP2 as well.</p> </li> </ul> </li> <li> <p>Deploy ALB controller.</p> <ul> <li> <p>Following the documentation, it is required to create an IAM role and deploy the ALB Controller.</p> </li> <li> <p>If you need to use already created ALB, please review this documentation and follow the steps below.</p> <ol> <li> <p>Create a target group manually and specify any IP address from the EKS subnet, it will be automatically replaced with the actual address by the ALB controller.</p> <ul> <li> <p>Target type is <code>IP addresses</code>.</p> </li> <li> <p>Target group name is any name. For example: <code>Genestack-ODM</code>.</p> </li> <li> <p><code>Protocol : Port</code> is <code>HTTP : 80</code></p> </li> <li> <p>IP address type is <code>IPv4</code></p> </li> <li> <p>VPC is <code>YOUR_EKS_VPC</code></p> </li> <li> <p>Protocol version is <code>HTTP1</code></p> </li> <li> <p>Health check protocol is <code>HTTP</code></p> </li> <li> <p>Health check path is <code>/frontend/health</code></p> </li> </ul> </li> <li> <p>Create a listener in ALB and attach the target group.</p> <ul> <li> <p>HTTP Path Pattern is <code>/*</code>.</p> </li> <li> <p>HTTP Host Header is <code>ODM_FQDN</code>. <code>ODM_FQDN</code> - ODM url without <code>https://</code> or <code>http://</code>. For example: <code>odm.genestack.com</code>.</p> </li> </ul> </li> <li> <p>Forward to target group above</p> </li> <li> <p>Set <code>nginx.ingress.enabled</code> parameter to <code>false</code> in ODM helm chart.</p> </li> <li> <p>Create and deploy TargetGroupBinding (example) in Kubernetes.</p> </li> <li> <p>Ensure that health checks in the target group have passed (after ODM deployment). You may need to allow access for the ALB subnet in the EC2 Security Group.</p> </li> </ol> </li> <li> <p>If you don't have an ALB.</p> <ul> <li>It will be created automatically during ODM deployment by ALB Controller.</li> </ul> </li> </ul> </li> <li> <p>[Optional] Deploy External DNS.</p> <ul> <li> <p>To automatically create records in Route53, it is recommended to use External DNS.</p> </li> <li> <p>Be careful when using it, you should limit the list of zones with which it can work. And if the zone is used for something else, then make sure that it will not delete records from there.</p> </li> </ul> </li> </ol>"},{"location":"deployment/clouds/aws/#configuration-examples","title":"Configuration examples","text":"CORS configuration for S3 <pre><code>[\n    {\n        \"AllowedHeaders\": [\n            \"accept\",\n            \"accept-language\",\n            \"Content-Type\"\n        ],\n        \"AllowedMethods\": [\n            \"PUT\"\n        ],\n        \"AllowedOrigins\": [\n            \"https://ODM_FQDN\"\n        ],\n        \"ExposeHeaders\": [],\n        \"MaxAgeSeconds\": 3000\n    }\n]\n</code></pre> IAM policy for S3 access <pre><code>{\n  \"Version\" : \"2012-10-17\",\n  \"Statement\" : [\n    {\n      \"Sid\" : \"ListObjectsInBucket\",\n      \"Effect\" : \"Allow\",\n      \"Action\" : [\n        \"s3:ListBucket\",\n        \"s3:GetBucketLocation\",\n        \"s3:ListBucketMultipartUploads\",\n        \"s3:ListBucketVersions\"\n      ],\n      \"Resource\" : [\"S3_BUCKET_ARN\"]\n    },\n    {\n      \"Sid\" : \"AllObjectActions\",\n      \"Effect\" : \"Allow\",\n      \"Action\" : [\n        \"s3:*Object*\",\n        \"s3:AbortMultipartUpload\",\n        \"s3:ListMultipartUploadParts\"\n      ],\n      \"Resource\" : [\"S3_BUCKET_ARN/*\"]\n    },\n    {\n      \"Sid\" : \"AllowUseOfTheKey\",\n      \"Effect\" : \"Allow\",\n      \"Action\" : [\n        \"kms:Encrypt\",\n        \"kms:Decrypt\",\n        \"kms:ReEncrypt*\",\n        \"kms:GenerateDataKey*\",\n        \"kms:DescribeKey\"\n      ],\n      \"Resource\" : [\"KMS_KEY_ARN\"]\n    }\n  ]\n}\n</code></pre> GP3 StorageClass example <pre><code>apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: gp3\nparameters:\n  type: gp3\nprovisioner: ebs.csi.aws.com\nvolumeBindingMode: Immediate\nallowVolumeExpansion: true\n</code></pre> TargetGroupBinding example <pre><code>apiVersion: elbv2.k8s.aws/v1beta1\nkind: TargetGroupBinding\nmetadata:\n  name: odm\n  namespace: odm\nspec:\n  ipAddressType: ipv4\n  serviceRef:\n    name: odm-nginx\n    port: 80\n  targetGroupARN: TARGET_GROUP_ARN\n</code></pre>"},{"location":"deployment/clouds/azure/","title":"Microsoft Azure","text":""},{"location":"deployment/clouds/azure/#required-types-of-resources","title":"Required types of resources","text":"<ul> <li>Azure FIles</li> <li>AKS<ul> <li>Azure Disk</li> <li>Azure App Gateway</li> <li>Azure DNS</li> </ul> </li> </ul> <p>Limitation</p> <p>At the moment this setup can only work with a Azure Files mount in a pods.</p>"},{"location":"deployment/clouds/azure/#recommended-steps-for-aks-configuration","title":"Recommended steps for AKS configuration","text":"<ol> <li> <p>Deploy AzureFile CSI Driver.</p> <ol> <li>Create Secret, PV and PVC.</li> </ol> </li> </ol>"},{"location":"deployment/clouds/azure/#configuration-examples","title":"Configuration examples","text":"Secret example. <pre><code>apiVersion: v1\ndata:\n  azurestorageaccountkey: xxxx\n  azurestorageaccountname: xxxx\nkind: Secret\nmetadata:\n  name: azure-secret\n  namespace: odm\ntype: Opaque\n</code></pre> PersistentVolume example. <pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pv-azurefile\nspec:\n  capacity:\n    storage: 100Gi\n  accessModes:\n    - ReadWriteMany\n  persistentVolumeReclaimPolicy: Retain\n  storageClassName: azurefile-csi\n  mountOptions:\n    - dir_mode=0777\n    - file_mode=0777\n    - uid=0\n    - gid=0\n    - mfsymlinks\n    - cache=strict\n    - nosharesock\n  csi:\n    driver: file.csi.azure.com\n    readOnly: false\n    volumeHandle: 1111-xxxx-23\n    volumeAttributes:\n      resourceGroup: xxxxx\n      shareName: xxxxx\n    nodeStageSecretRef:\n      name: azure-secret\n      namespace: odm\n</code></pre> PersistentVolumeClaim example. <pre><code>kind: PersistentVolumeClaim\napiVersion: v1\nmetadata:\n  name: pvc-azurefile\n  namespace: odm\nspec:\n  accessModes:\n    - ReadWriteMany\n  resources:\n    requests:\n      storage: 100Gi\n  volumeName: pv-azurefile\n  storageClassName: azurefile-csi\n</code></pre>"},{"location":"deployment/helm/how-to-deploy/","title":"How to deploy","text":""},{"location":"deployment/helm/how-to-deploy/#requirements","title":"Requirements","text":"<ul> <li> <p>Kubernetes</p> </li> <li> <p>Helm 3+</p> </li> <li> <p>AWS CLI for getting permissions to download Helm chart</p> </li> </ul>"},{"location":"deployment/helm/how-to-deploy/#deployment-information","title":"Deployment Information","text":"<ul> <li> <p>All main ODM settings are presented in the Deployment Helm Chart.</p> </li> <li> <p>To deploy ODM <code>StorageClass</code> and <code>IngressClass</code> have to be configured in Kubernetes Cluster.</p> </li> <li> <p>To enable automatic metrics collection when using Prometheus Operator, configure the <code>serviceMonitor</code> parameter in the Helm Chart.</p> </li> <li> <p>We provide a tool that automates the process of updating credentials for ECR, where our container images are hosted. This tool ensures seamless access to ECR by handling credential rotation.</p> <ul> <li> <p>It's important to note that the ECR password is valid for a duration of 12 hours.</p> </li> <li> <p>If you are using AWS EKS, you do not need this tool. Access to our ECR will be provided upon request.</p> </li> </ul> </li> <li> <p>To utilize external storage solutions that are compatible with Distributed File System (DFS) within a Kubernetes environment, it is necessary to first establish a Persistent Volume Claim (PVC).</p> </li> </ul>"},{"location":"deployment/helm/how-to-deploy/#deployment-process","title":"Deployment process","text":"<ol> <li> <p>Preparing to log in to ECR.</p> <ul> <li> <p>If you are not hosting on AWS, Configure AWS CLI (see Long-term credentials) with the credentials provided by our support team (this is necessary to access the ECR).</p> </li> <li> <p>If you are hosting on AWS, ensure that you have the AmazonEC2ContainerRegistryReadOnly policy or a similar one enabled for access to ECR.</p> </li> </ul> </li> <li> <p>Login to ECR</p> <pre><code>aws ecr get-login-password --region us-east-1 | helm registry login --username AWS \\\n--password-stdin 091468197733.dkr.ecr.us-east-1.amazonaws.com\n</code></pre> </li> <li> <p>Download Helm Chart (the latest version will be downloaded automatically)</p> <pre><code>helm pull oci://091468197733.dkr.ecr.us-east-1.amazonaws.com/genestack/chart/odm\n</code></pre> </li> <li> <p>Untar the archive.</p> <pre><code>tar xvf odm-*.tgz\n</code></pre> </li> <li> <p>Take a look to a default <code>values.yaml</code> and to a <code>odm/example-values</code> directory, the most general file in there is <code>recomendations.yaml</code>, make changes according to your infrastructure and requirements in separate file, e.g. <code>custom-values.yaml</code>.</p> </li> <li> <p>Deploy</p> <ul> <li>In this example odm used as a release name, also as a namespace name</li> </ul> <pre><code>helm upgrade -i odm --create-namespace -n odm -f custom-values.yaml ./\n</code></pre> </li> </ol>"},{"location":"deployment/release-notes/v1.50-v1.59/","title":"Release notes","text":""},{"location":"deployment/release-notes/v1.50-v1.59/#version-156","title":"Version 1.56","text":""},{"location":"deployment/release-notes/v1.50-v1.59/#export-metrics-to-genestack","title":"Export metrics to Genestack","text":"<p>Fluent-bit was introduced as an extra service tasked with collecting and dispatching metrics in Prometheus format to a Genestack.</p> <p>These metrics encompass technical and/or product-related data, devoid of any sensitive information.</p> <p>If you wish to deactivate this functionality, you can do so by configuring the following parameter:</p> <pre><code>fluent-bit:\n  enabled: false\n</code></pre>"},{"location":"deployment/release-notes/v1.50-v1.59/#helm-configuration-changes","title":"Helm configuration changes","text":"<p>Now organization name and hostname are in a <code>global</code> section:</p> <p>From:</p> <pre><code>odmFrontendHostname: odm.local\napplications:\n  configurationFiles:\n    \"application.yaml\":\n      frontend:\n        ui:\n          organization:\n            name: \"Genestack\"\n</code></pre> <p>To:</p> <pre><code>global:\n  hostname: odm.local\n  organizationName: \"Genestack\"\n</code></pre>"},{"location":"deployment/release-notes/v1.50-v1.59/#version-155","title":"Version 1.55","text":""},{"location":"deployment/release-notes/v1.50-v1.59/#configure-odm-usage-together-with-encrypted-s3-bucket-sse-kms-and-sse-s3-only","title":"Configure ODM usage together with encrypted S3 bucket (SSE-KMS and SSE-S3 only)","text":""},{"location":"deployment/release-notes/v1.50-v1.59/#introduction","title":"Introduction","text":"<p>You can find configuration examples in the ODM Helm chart.</p> <p>In case you have several AWS credentials in your configuration, you need to modify only the credentials for accessing the bucket in specified as <code>frontend.aws.bucket</code>.</p>"},{"location":"deployment/release-notes/v1.50-v1.59/#sse-kms","title":"SSE-KMS","text":"<p>To enable uploading into an SSE-KMS encrypted bucket, you need to customize <code>func-file</code> configuration. The following configuration example uses a bucket encrypted by SSE-KMS with the name <code>&lt;BUCKET_NAME&gt;</code>. The bucket configuration should specify the algorithm <code>aws:kms</code> as <code>preferredAlgorithm</code>. Additionally, the property <code>kmsCmkId</code> should be added with a value equal to key id <code>arn:aws:kms:...</code> if the bucket policy requires this key to be explicitly send on PUT request. The <code>func-file</code> section in the configuration should look like this:</p>"},{"location":"deployment/release-notes/v1.50-v1.59/#sse-s3","title":"SSE-S3","text":"<p>The SSE-S3 encryption type is default to the most buckets. To force ODM request this type of encryption from S3 provider for <code>&lt;BUCKET_NAME&gt;</code>, you need to specify the <code>preferredAlgorithm</code> property with the value <code>AES256</code>:</p>"},{"location":"deployment/release-notes/v1.50-v1.59/#on-storage_config-section-configuration-in-func-file","title":"On <code>storage_config</code> section configuration in <code>func-file</code>","text":"<p>Keep in mind that <code>func-file</code> reads the <code>storage_config</code> section sequentially. You can create specific configurations for individual buckets, e.g., if one has SSE-KMS encryption while others do not. To do this, as the first item in the list, you'll need to specify the bucket with the specific configuration and its name. Then, provide the general configuration for the other buckets using the wildcard symbol <code>*</code>. ODM will only upload files to the bucket, specified as <code>frontend.aws.bucket</code> property, regardless to <code>storage_config</code> section.</p>"},{"location":"deployment/release-notes/v1.50-v1.59/#genestack-pod-separation","title":"Genestack pod separation","text":"<p>Example on the image section, but it's applicable for sections with backend/frontend separation.</p> <p>ApplicationSettings changes showed separately:</p> <p>From:</p> <pre><code>genestack:\n  image:\n    backend:\n      registry: 091468197733.dkr.ecr.us-east-1.amazonaws.com\n      repository: genestack/core\n      pullPolicy: Always\n      pullSecrets: []\n    frontend:\n      registry: 091468197733.dkr.ecr.us-east-1.amazonaws.com\n      repository: genestack/applications\n      pullPolicy: Always\n      pullSecrets: []\n</code></pre> <p>To:</p> <pre><code>core:\n  image:\n    registry: 091468197733.dkr.ecr.us-east-1.amazonaws.com\n    repository: genestack/core\n    pullPolicy: Always\n    pullSecrets: []\n\napplications:\n  image:\n    registry: 091468197733.dkr.ecr.us-east-1.amazonaws.com\n    repository: genestack/applications\n    pullPolicy: Always\n    pullSecrets: []\n</code></pre>"},{"location":"deployment/release-notes/v1.50-v1.59/#application-settings-rework","title":"Application settings rework","text":"<p>From:</p> <pre><code>genestack:\n  applicationSettings:\n    backend:\n      properties:\n        # backend.properties file content\n      propertiesAuth:\n        # backend-credentials.properties file content\n      propertiesLimits:\n        # limits.yaml file content\n      predefinedSystemUsers:\n        # token and password for technical odm users\n      predefinedUsers:\n        # predefined-users.json file content\n    frontend:\n      properties:\n        # frontend.properties file content\n        \"google.openid.ini\":\n          # google.openid.ini file content\n        \"microsoft.openid.ini\":\n          # microsoft.openid.ini file content\n        \"okta.openid.ini\":\n          # okta.openid.ini file content\n      propertiesAuth:\n        # frontend-credentials.properties file content\n      monitoringThresholds:\n        # monitoring-thresholds.yaml file content\n    saml:\n      # saml directory content\n</code></pre> <p>To:</p> <pre><code>core:\n  configurationFiles:\n    \"application.yaml\":\n      # backend.properties and backend-credentials.properties files content in YAML format\n    \"settings.py.local\":\n      # settings.py.local file content\n  secretFiles:\n    # saml directory content\n\napplications:\n  configurationFiles:\n    \"application.yaml\":\n    # frontend.properties and frontend-credentials.properties files content in YAML format\n    \"google.openid.ini\":\n    # google.openid.ini file content\n    \"microsoft.openid.ini\":\n    # microsoft.openid.ini file content\n    \"okta.openid.ini\":\n    # okta.openid.ini file content\n</code></pre>"},{"location":"deployment/release-notes/v1.50-v1.59/#high-level-paths-renaming-in-valuesyaml","title":"High-level paths renaming in values.yaml","text":""},{"location":"deployment/release-notes/v1.50-v1.59/#solr","title":"Solr","text":"<p>From:</p> <pre><code>index: {}  # Solr configuration\n</code></pre> <p>To:</p> <pre><code>solr: {}  # Solr configuration\n</code></pre>"},{"location":"deployment/release-notes/v1.50-v1.59/#clickhouse","title":"Clickhouse","text":"<p>From:</p> <pre><code>txIndex: {}  # Clickhouse configuration\n</code></pre> <p>To:</p> <pre><code>clickhouse: {}  # Clickhouse configuration\n</code></pre>"},{"location":"deployment/release-notes/v1.50-v1.59/#mysql","title":"Mysql","text":"<p>From:</p> <pre><code>db: {}  # Mysql configuration\n</code></pre> <p>To:</p> <pre><code>mysql: {}  # Mysql configuration\n</code></pre>"},{"location":"deployment/release-notes/v1.50-v1.59/#nginx","title":"Nginx","text":"<p>From:</p> <pre><code>proxy: {}  # Nginx configuration\n</code></pre> <p>To:</p> <pre><code>nginx: {}  # Nginx configuration\n</code></pre>"},{"location":"deployment/requirements/external-services/","title":"External Services","text":"<ul> <li>As a storage solution for the source data ODM supports S3 and any Distribute File System that can be represented in Kubernetes as a StorageClass with RWM attribute. e.g. (NFS, EFS)</li> <li>For notifications and secure tokens distribution SMTP service is required.</li> <li>For SSO (Single Sign-On) functionality an Identity Provider is required.</li> </ul>"},{"location":"deployment/requirements/hardware/","title":"Hardware","text":"<ul> <li>We recommend allocating 16 cores 128GB of memory for production environments.</li> <li>It is necessary to provide multiple disks for databases and internal services. You can use any solution that works with Kubernetes (AWS EBS, Azure Disks, etc.). An important note: for optimal performance, we strongly recommend using SSDs.</li> <li>The operating system can be any distribution of Linux (Ubuntu, CentOS, RedHat, Amazon Linux, etc). Preferably, use the latest versions.</li> <li>The container runtime processor architecture must be x86-64.</li> </ul>"},{"location":"deployment/requirements/kubernetes/","title":"Kubernetes","text":"<ul> <li>Any distribution of Kubernetes could be used, e.g.: EKS, AKS, Rancher, Vanilla Kubernetes. Of the known limitations, we have not tested with Redhat OpenShift.</li> <li>ODM requires to store a state inside of Kubernetes, this is under StorageClass and the corresponding controller responsability.</li> <li>For publishing ODM we use Ingress, it requires a IngressClass and the corresponding controller.</li> <li>(Recommendation) To work with SSL/TLS, for Ingress, provide certificates via Kubernetes secrets or configure them on an external Load Balancer.</li> </ul>"},{"location":"deployment/single-sign-on/sso/","title":"About SSO in ODM","text":"<p>For authentication, ODM supports the OpenID and SAML.</p> <p>For user and group synchronization, it supports the SCIM.</p> <p>Important information</p> <ul> <li> <p>ODM can work with only one protocol (OpenID or SAML) at a time.</p> </li> <li> <p>With OpenID, you can use OAuth tokens to connect to the ODM API (documentation for Azure)</p> </li> </ul>"},{"location":"deployment/single-sign-on/openid/azure/","title":"Azure AD setup","text":"<p>This section explains how to integrate ODM with AzureAD to use AzureAD tenant as OpenID Connect provider, OAuth 2.0 server.</p>"},{"location":"deployment/single-sign-on/openid/azure/#create-odm-application-configuration-in-azuread","title":"Create ODM application configuration in AzureAD","text":"<ol> <li> <p>Go to Azure Portal App Registration</p> </li> <li> <p>Navigate to Enterprise applications \u2013&gt; All applications</p> </li> <li> <p>Press \"New application\" button, then press \"Create your own application\" button</p> </li> <li> <p>Assign the application name, select \"Non-gallery\" application type, and press \"Create\" button</p> </li> </ol> <p>Warning</p> <p>Do not create the application via Azure Active Directory \u2013&gt; App registrations, because applications created that way do not support SCIM user provisioning.</p>"},{"location":"deployment/single-sign-on/openid/azure/#configure-openid-connect-client","title":"Configure OpenID Connect client","text":"<ol> <li> <p>Navigate to Azure Active Directory \u2013&gt; App registrations \u2013&gt; {YOUR-APPLICATION}</p> </li> <li> <p>Under \"Overview\" menu item:</p> <ol> <li> <p>Copy the \"Application (client) ID\" value. You will need to save this alue as <code>clientId</code> ODM configuration parameter</p> </li> <li> <p>Press Endpoints button in toolbar, and copy OpenID Connect metadata document URL. It should look like <code>https://login.microsoftonline.com/{tenant}/v2.0/.well-known/openid-configuration</code>.     You will need to save it as <code>discoveryDocumentUri</code> ODM configuration parameter. Refer to Fetch the OpenID Connect metadata document for details about OpenID Connect discovery.</p> </li> </ol> </li> <li> <p>Under \"Branding and properties\" menu item, configure \"Home page URL\" (e.g. as <code>https://ODM-HOST</code>) and press \"Save\" button</p> </li> <li> <p>Under \"Authentication\" menu item:</p> <ol> <li> <p>Press \"Add a platform\" button under \"Platform configurations\" section</p> <ol> <li> <p>Select \"Web\" application type</p> </li> <li> <p>Specify ODM redirect URI, e.g. <code>https://ODM-HOST/frontend/endpoint/microsoft/back</code></p> </li> <li> <p>Press \"Configure\" button</p> </li> </ol> </li> <li> <p>Disable all tokens for \"Implicit grant and hybrid flows\"</p> </li> <li> <p>Press \"Save\" button</p> </li> </ol> </li> <li> <p>Under \"Certificates and secrets\" menu item:</p> <ol> <li> <p>Press \"New client secret\" button under \"Client secrets\" section, specify the secret description, choose the expiration time, and press \"Add\" button</p> </li> <li> <p>Find the newly added client secret in the table and copy the client secret value (from \"Value\" column). You will need to save this value as <code>clientSecret</code> ODM configuration parameter</p> </li> </ol> </li> <li> <p>Under \"API permissions\" menu item:</p> <ol> <li> <p>Press \"Add a permission\" button under \"Configured permissions\" section</p> <ol> <li> <p>Select \"Microsoft Graph\" application type</p> </li> <li> <p>Select \"Delegated permissions\"</p> </li> <li> <p>On the menu \"OpenId permissions\" select: <code>email</code>, <code>openid</code>, <code>profile</code>, <code>offline_access</code></p> </li> <li> <p>Press \"Add permission\" button</p> </li> </ol> </li> <li> <p>Press \"Grant admin consent for {YOUR ORGANIZATION}\" button under \"Configured permissions\" section</p> </li> </ol> </li> </ol> <p>Attention</p> <p>You may want to review settings under \"Supported account types\" and update them as appropriate for your use case. Do not forget to press the \"Save\" button.</p> <p>Now you can configure ODM to use AzureID as OpenID Connect provider. You can find configuration examples in the Helm chart.</p>"},{"location":"deployment/single-sign-on/openid/azure/#configure-oauth-resource-server","title":"Configure OAuth resource server","text":"<p>ODM exposes REST APIs which can only be called by other applications. These client applications can use OAuth 2.0 access tokens, issued by Authorization Server, to authorize REST API requests to ODM.</p> <p>To make it work, you need to establish trust relationships between ODM and AzureAD (it will play the Authorization Server role). You can do this by configuring OpenID Connect integration (see Configure OpenID Connect client section above).</p> <p>After that you need to provide AzureAD with necessary information about ODM. Navigate to Azure Active Directory \u2013&gt; App registrations \u2013&gt; {YOUR-APPLICATION} and do the following:</p> <ol> <li> <p>Set up OAuth scopes for ODM:</p> <ol> <li> <p>Open \"Expose an API\" menu item</p> </li> <li> <p>Set \"Application ID URI\" if it is not set already:</p> <ol> <li> <p>Press the \"Set\" hyperlink to the right of \"Application ID URI\" label</p> </li> <li> <p>Leave the default \"Application ID URI\" value which is <code>api://{clientId}</code></p> </li> <li> <p>Press \"Save\" button</p> </li> </ol> </li> <li> <p>Define a single default scope for ODM REST API clients:</p> <ol> <li> <p>Press \"Add a scope\" button under \"Scopes defined by this API\" section</p> </li> <li> <p>Set \"Scope name\" to whatever you like, e.g. <code>default</code></p> </li> <li> <p>Set \"Who can consent?\" to \"Admins and users\"</p> </li> <li> <p>Set \"Admin consent display name\" to \"Access user data in ODM\"</p> </li> <li> <p>Set \"Admin consent description\" to \"Allows the app to read signed-in user's data in ODM\"</p> </li> <li> <p>Set \"User consent display name\" to \"Access your data in ODM\"</p> </li> <li> <p>Set \"User consent description\" to \"Allows the app to read your data in ODM\"</p> </li> <li> <p>Set \"State\" to \"Enabled\"</p> </li> <li> <p>Press \"Add scope\" button</p> </li> </ol> </li> <li> <p>Tell AzureAD which applications should be able to retrieve access tokens from AzureAD to access ODM REST API endpoints:</p> <ol> <li> <p>Press \"Add a client application\" button under \"Authorized client applications\" section</p> </li> <li> <p>Set \"Client ID\" to the <code>clientId</code> value of the application that will retrieve access tokens from AzureAD to access ODM REST APIs. This client application must have its own App registration in AzureAD where it receives its own <code>clientId</code>, different from the <code>clientId</code> value used to configure ODM</p> </li> <li> <p>Select the <code>api://{clientId}/default</code> scope from the list of scopes under \"Authorized scopes\"</p> </li> <li> <p>Press \"Add application\" button</p> </li> </ol> </li> <li> <p>Repeat the previous step for every client application in case you have many of them</p> </li> </ol> </li> <li> <p>Configure AzureAD to issue to ODM clients Access Tokens version 2 (otherwise access tokens will not be compatible with configuration from OpenID Connect discovery document; see Note about access token version section below):</p> <ol> <li> <p>Open \"Manifest\" menu item</p> </li> <li> <p>Find <code>accessTokenAcceptedVersion</code> parameter in the manifest JSON</p> </li> <li> <p>Set the value of <code>accessTokenAcceptedVersion</code> to <code>2</code></p> </li> <li> <p>Press \"Save\" button</p> </li> </ol> </li> </ol> <p>Now AzureAD is configured to issue access tokens with the <code>api://{clientId}/default</code> scope to applications that want to access ODM REST APIs using OAuth 2.0 access tokens.</p>"},{"location":"deployment/single-sign-on/openid/azure/#note-about-access-token-version","title":"Note about access token version","text":"<p>ODM is configured to use version 2 of OpenID Connect protocol implementation in AzureAD, as defined by the discovery document URL: <code>https://login.microsoftonline.com/{tenant}/v2.0/.well-known/openid-configuration?appId={clientId}</code></p> <p>However, for access tokens AzureAD uses the version 1 format by default, which is incompatible with configuration from v2 OpenID Connect discovery document: <code>iss</code> claim in v1 access token format has values like <code>https://sts.windows.net/{uuid}/</code> while the expected <code>iss</code> claim format in v2 configuration is <code>https://login.microsoftonline.com/{uuid}/v2.0</code>.</p> <p>Therefore, we need to tell AzureAD explicitly to use v2 format of access tokens, which is currently possible only by changing <code>accessTokenAcceptedVersion</code> parameter in application manifest manually. Refer to manifest reference for details.</p>"},{"location":"deployment/single-sign-on/openid/azure/#configure-user-and-group-provisioning","title":"Configure user and group provisioning","text":"<p>An article about SCIM can be found here SCIM provisioning</p>"},{"location":"deployment/single-sign-on/openid/google/","title":"Google Workspace setup","text":"<p>This section explains how to integrate ODM with Google Workspace to use Google as OpenID Connect provider.</p> <p>Official documentation</p>"},{"location":"deployment/single-sign-on/openid/google/#create-google-oauth-keys","title":"Create Google OAuth keys","text":"<ol> <li> <p>Go to Google Console</p> </li> <li> <p>Click Create Credentials, then click OAuth Client ID in the drop-down menu</p> </li> <li> <p>Enter the following:</p> <ul> <li> <p>Application Type: Web Application</p> </li> <li> <p>Name: Specify a name for your app</p> </li> <li> <p>Authorized JavaScript Origins: <code>https://ODM-HOST</code></p> </li> <li> <p>Authorized Redirect URLs: <code>https://ODM-HOST/frontend/endpoint/google/back</code></p> </li> </ul> </li> <li> <p>Click Create</p> </li> <li> <p>Copy the <code>Client ID</code> and <code>Client Secret</code> from the OAuth Client modal</p> </li> </ol> <p>Now you can configure ODM to use Google as OpenID Connect provider. You can find configuration examples in the Helm chart.</p>"},{"location":"deployment/single-sign-on/openid/okta/","title":"Okta setup","text":"<p>This section explains how to integrate ODM with Okta to use Okta as OpenID Connect provider.</p> <p>Official documentation</p>"},{"location":"deployment/single-sign-on/openid/okta/#launch-the-wizard","title":"Launch the Wizard","text":"<ol> <li> <p>In the Admin Console, go to Applications -&gt; Applications.</p> </li> <li> <p>Click Create App Integration.</p> </li> <li> <p>To create an OIDC app integration, select OIDC - OpenID Connect as the Sign-in method.</p> </li> <li> <p>Choose the type of application to integrate with Okta. Select Web Application.</p> </li> <li> <p>Click Next.</p> </li> </ol>"},{"location":"deployment/single-sign-on/openid/okta/#configure-initial-settings","title":"Configure initial settings","text":"<ol> <li> <p>In General Settings</p> <ul> <li> <p>App integration name: Specify a name for your app integration</p> </li> <li> <p>Grant type: select Authorization Code and Interaction Code</p> </li> <li> <p>Sign-in redirect URIs: <code>https://ODM-HOST/frontend/endpoint/okta/back</code></p> </li> </ul> </li> <li> <p>Next, you can follow the official instructions.</p> </li> </ol>"},{"location":"deployment/single-sign-on/openid/okta/#configure-oidc-settings","title":"Configure OIDC settings","text":"<ul> <li>Copy the Client ID and the Client Secret from General page.</li> </ul> <p>Now you can configure ODM to use Okta as OpenID Connect provider. You can find configuration examples in the Helm chart.</p>"},{"location":"deployment/single-sign-on/saml/google/","title":"Google Workspace setup","text":"<p>This section explains how to integrate ODM with Google Workspace to use Google as SAML service provider.</p> <p>Official documentation</p>"},{"location":"deployment/single-sign-on/saml/google/#create-google-saml-app","title":"Create Google SAML app","text":"<ol> <li> <p>In the GSuite Admin Cosole, go to Apps -&gt; Web and mobile apps</p> </li> <li> <p>Click Add app -&gt; Add custom SAML app</p> <ol> <li> <p>App details</p> <ul> <li>App name: Specify a name for your app</li> </ul> </li> <li> <p>Google Identity Provider details</p> <ul> <li> <p>Copy SSO URL and Entity ID</p> </li> <li> <p>Download the certificate, it will be useful for setting up ODM</p> </li> </ul> </li> <li> <p>Service provider details</p> <ul> <li> <p>ACS URL: <code>https://ODM-HOST/frontend/endpoint/AssertionConsumer</code></p> </li> <li> <p>Entity ID: <code>https://ODM-HOST/frontend/endpoint/SamlSpMetadata</code></p> </li> <li> <p>Start URL: <code>https://ODM-HOST/</code></p> </li> <li> <p>Signed Response: <code>off</code> (see below)</p> </li> <li> <p>Name ID</p> <ul> <li> <p>Name ID format: <code>EMAIL</code></p> </li> <li> <p>Name ID: <code>Basic Information / Primary Email</code></p> </li> </ul> </li> </ul> </li> <li> <p>Attribute mapping</p> <ul> <li> <p>Attributes: Click Add Mapping to define the following attributes</p> <ul> <li> <p><code>Basic Information / Primary Email</code> -&gt; <code>urn:mace:dir:attribute-def:mail</code></p> </li> <li> <p><code>Basic Information / First Name</code> -&gt; <code>urn:mace:dir:attribute-def:givenName</code></p> </li> <li> <p><code>Basic Information / Last Name</code> -&gt; <code>urn:mace:dir:attribute-def:sn</code></p> </li> </ul> </li> </ul> </li> <li> <p>Click Finish</p> </li> <li> <p>You\u2019ll be redirected to \u201cApplication settings\" page.</p> <ul> <li>Click User access and then change Service status to ON for everyone. SAVE the change.</li> </ul> </li> </ol> </li> </ol> <p>Warning</p> <p>As of Mar 4, 2020 Signed Response checkbox behaves weirdly:</p> <ul> <li> <p>when it is <code>off</code>, response itself is unsigned, but assertions are signed</p> </li> <li> <p>when the checkbox is <code>on</code>, response becomes signed, but assertions for some reason are unsigned</p> </li> </ul> <p>We do not support the latter combination, hence in Google Suite SAML Signed Response option should be turned off.</p>"},{"location":"deployment/single-sign-on/saml/google/#certificate-preparation","title":"Certificate preparation","text":"<p>You need to create the necessary certificates for ODM.</p> <ol> <li> <p>In step 2b, you downloaded the certificate.</p> <ol> <li> <p>Convert it to <code>idp.key</code>.</p> <pre><code>openssl x509 -outform der -in downloaded_certificate.pem -out idp.key\n</code></pre> </li> <li> <p>Convert <code>idp.key</code> to base64 format</p> <pre><code>cat idp.key | base64\n</code></pre> </li> </ol> </li> <li> <p>Create new certificates</p> <ol> <li> <p>Generate <code>sp_x509_pem.crt</code></p> <ul> <li><code>ODM-HOST</code> is the server name without http/https, for example, <code>odm.example.com</code>.</li> </ul> <pre><code>export SAML_SP_HOSTNAME=\"ODM-HOST\"\n\nopenssl req \\\n-x509 \\\n-nodes \\\n-newkey rsa:2048 \\\n-keyout sp_pem.key \\\n-out sp_x509_pem.crt \\\n-subj \"/C=UK/ST=England/L=Cambridge/O=Genestack/OU=Genestack/CN=${SAML_SP_HOSTNAME}\" \\\n-days 3650\n</code></pre> </li> <li> <p>Generate <code>sp_pkcs8_der.key</code></p> <pre><code>openssl pkcs8 \\\n-topk8 \\\n-inform PEM \\\n-outform DER \\\n-in sp_pem.key \\\n-out sp_pkcs8_der.key \\\n-nocrypt\n</code></pre> </li> <li> <p>Convert <code>sp_x509_pem.crt</code> to base64 format</p> <pre><code>cat sp_x509_pem.crt | base64\n</code></pre> </li> <li> <p>Convert <code>sp_pkcs8_der.key</code> to base64 format</p> <pre><code>cat sp_pkcs8_der.key | base64\n</code></pre> </li> <li> <p>Update the Helm chart with the provided information.</p> </li> </ol> </li> </ol> <p>Now you can configure ODM to use Google as SAML service provider. You can find configuration examples in the Helm chart.</p>"},{"location":"deployment/single-sign-on/saml/okta/","title":"Okta setup","text":"<p>This section explains how to integrate ODM with Okta to use Okta as SAML service provider.</p> <p>Official documentation</p>"},{"location":"deployment/single-sign-on/saml/okta/#create-okta-saml-app","title":"Create Okta SAML app","text":"<ol> <li> <p>In the Admin Console, go to Applications -&gt; Applications</p> </li> <li> <p>Click Create App Integration</p> </li> <li> <p>Select SAML 2.0 as the Sign-in method</p> <ol> <li> <p>General settings</p> <ul> <li>App name: Specify a name for your app</li> </ul> </li> <li> <p>Configure SAML</p> <ol> <li> <p>General</p> <ul> <li> <p>Single sign-on URL: <code>https://ODM-HOST/frontend/endpoint/AssertionConsumer</code></p> </li> <li> <p>Audience URI (SP Entity ID): <code>https://ODM-HOST/frontend/endpoint/SamlSpMetadata</code></p> </li> <li> <p>Name ID format: <code>EmailAddress</code></p> </li> <li> <p>Application username: <code>Email</code></p> </li> </ul> </li> <li> <p>Attribute Statements (optional)</p> <ul> <li> <p><code>urn:mace:dir:attribute-def:mail</code> -&gt; <code>user.email</code></p> </li> <li> <p><code>urn:mace:dir:attribute-def:givenName</code> -&gt; <code>user.firstName</code></p> </li> <li> <p><code>urn:mace:dir:attribute-def:sn</code> -&gt; <code>user.lastName</code></p> </li> </ul> </li> </ol> </li> <li> <p>Feedback</p> <ul> <li>App type: This is an internal app that we have created</li> </ul> </li> <li> <p>Click Finish</p> </li> <li> <p>You\u2019ll be redirected to Sign On page.</p> <ul> <li>In the SAML Signing Certificates section, generate a new one or download an existing certificate. It will be needed for configuring ODM.</li> </ul> </li> </ol> </li> </ol>"},{"location":"deployment/single-sign-on/saml/okta/#certificate-preparation","title":"Certificate preparation","text":"<p>You need to create the necessary certificates for ODM.</p> <ol> <li> <p>In step E, you downloaded the certificate.</p> <ol> <li> <p>Convert it to <code>idp.key</code>.</p> <pre><code>openssl x509 -outform der -in okta.cert -out idp.key\n</code></pre> </li> <li> <p>Convert <code>idp.key</code> to base64 format</p> <pre><code>cat idp.key | base64\n</code></pre> </li> </ol> </li> <li> <p>Create new certificates</p> <ol> <li> <p>Generate <code>sp_x509_pem.crt</code></p> <ul> <li><code>ODM-HOST</code> is the server name without http/https, for example, <code>odm.example.com</code>.</li> </ul> <pre><code>export SAML_SP_HOSTNAME=\"ODM-HOST\"\n\nopenssl req \\\n-x509 \\\n-nodes \\\n-newkey rsa:2048 \\\n-keyout sp_pem.key \\\n-out sp_x509_pem.crt \\\n-subj \"/C=UK/ST=England/L=Cambridge/O=Genestack/OU=Genestack/CN=${SAML_SP_HOSTNAME}\" \\\n-days 3650\n</code></pre> </li> <li> <p>Generate <code>sp_pkcs8_der.key</code></p> <pre><code>openssl pkcs8 \\\n-topk8 \\\n-inform PEM \\\n-outform DER \\\n-in sp_pem.key \\\n-out sp_pkcs8_der.key \\\n-nocrypt\n</code></pre> </li> <li> <p>Convert <code>sp_x509_pem.crt</code> to base64 format</p> <pre><code>cat sp_x509_pem.crt | base64\n</code></pre> </li> <li> <p>Convert <code>sp_pkcs8_der.key</code> to base64 format</p> <pre><code>cat sp_pkcs8_der.key | base64\n</code></pre> </li> <li> <p>Update the Helm chart with the provided information.</p> </li> </ol> </li> </ol> <p>Now you can configure ODM to use Okta as SAML service provider. You can find configuration examples in the Helm chart.</p>"},{"location":"deployment/single-sign-on/scim/azure/","title":"Azure AD setup","text":"<p>This section explains how to enable user and group provisioning from AzureAD into ODM via SCIM protocol.</p> <p>Attention</p> <p>Before proceeding with SCIM configuration, make sure you have set up OpenID.</p>"},{"location":"deployment/single-sign-on/scim/azure/#configure-user-and-group-provisioning","title":"Configure user and group provisioning","text":"<p>ODM exposes SCIM API endpoints at <code>https://ODM-HOST/frontend/rs/genestack/scim-integration/default-released/scim</code>. AzureAD requires access to these API endpoints in order to provision users and groups into ODM.</p> <p>If your ODM instance is directly accessible from AzureAD servers, you can use the SCIM endpoint above when configuring provisioning in AzureAD. Otherwise, you need to enable access via HTTP protocol from AzureAD servers to the ODM SCIM endpoints, and then use the corresponding external SCIM endpoint URL as configured.</p> <p>Below are configuration steps for AzureAD portal:</p> <ol> <li> <p>Navigate to Enterprise applications \u2013&gt; All applications \u2013&gt; {YOUR-APPLICATION} \u2013&gt; Provisioning</p> </li> <li> <p>Press \"Get started\" button and configure provisioning settings:</p> <ol> <li> <p>Set \"Provisioning Mode\" to \"Automatic\"</p> </li> <li> <p>Set \"Tenant URL\" to the ODM SCIM endpoint URL mentioned above</p> </li> <li> <p>Set \"Secret Token\" to a Genestack API token generated for a dedicated ODM service account</p> </li> <li> <p>Press \"Test Connection\" button</p> </li> <li> <p>If the test is successful, press \"Save\" button; otherwise ensure your configuration is correct, refer to ODM Administration Guide, or contact ODM support for assistance.</p> </li> </ol> </li> <li> <p>Before the first synchronisation we recommend you check the list of groups and users in ODM and add the same users to the same groups in AD.</p> </li> <li> <p>Press \"Start provisioning\" button</p> </li> </ol>"},{"location":"deployment/troubleshooting/aws-s3/","title":"Problems with S3","text":""},{"location":"deployment/troubleshooting/aws-s3/#func-file-service","title":"Func-file service","text":"<ul> <li> <p><code>Can't (re-)connect to: https://bucket-name.s3.eu-west-1.amazonaws.com/file-name ... Access Denied</code> - This error indicates that there is an issue with:</p> <ul> <li> <p>Access to S3.</p> </li> <li> <p>Access to the KMS key (if the KMS key is used for encrypting data in the s3 bucket).</p> </li> <li> <p>KMS key is not specified in the ODM configuration <code>func-file</code> (if the KMS key is used for encrypting data in the s3 bucket).</p> </li> </ul> </li> </ul>"},{"location":"deployment/troubleshooting/azure-scim/","title":"Problems with Azure SCIM provisioning","text":""},{"location":"deployment/troubleshooting/azure-scim/#azure-application","title":"Azure Application","text":"<ul> <li><code>SystemForCrossDomainIdentityManagementCredentialValidationUnavailable</code> - The server is unavailable for Azure to start synchronization (this process is initiated by Azure). You need to make ODM accessible from the Internet (or through internal networks if you are using Azure) so that Azure SCIM provisioning can connect to it.</li> </ul>"},{"location":"deployment/troubleshooting/azure-sso/","title":"Problems with Azure SSO","text":""},{"location":"deployment/troubleshooting/azure-sso/#applications-service","title":"Applications service","text":"<ul> <li><code>Claim \\\"email\\\" is not present in JWT</code> - means that the user has an empty email field (this is a required field).</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/","title":"Release notes","text":""},{"location":"usage/release-notes/v1.20-v1.29/#129-21-sep-2020","title":"1.29 (21 Sep 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#newupdated-features-in-this-release","title":"New/updated features in this release","text":"<ul> <li>Client-specific features</li> <li>Much improved single cell study loading</li> <li>Faster performance on single cell omics (up to 2x faster) and streaming (up to 10x faster) queries</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#fixed-issues","title":"Fixed issues","text":"<ul> <li>Fixed an issue causing slow performance of the <code>sampleUser</code> endpoint</li> <li>Previous streaming data export issue has been resolved</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#known-issues","title":"Known issues","text":"<ul> <li>Filters in the samples table in Metadata Editor do not work for multi-value fields</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#128-8-sep-2020","title":"1.28 (8 Sep 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#newupdated-features-in-this-release_1","title":"New/updated features in this release","text":"<ul> <li>New user interface for groups administration</li> <li>Improved data handling performance</li> <li>New asynchronous linking service endpoints are available. See below for a list of endpoints, and the swagger documentation for further usage details</li> <li>The Python helper script for loading data to ODM has been updated to use the asynchronous REST APIs for better handling of large datasets</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#fixed-issues_1","title":"Fixed issues","text":"<ul> <li>Linking group files for large datasets via REST API should avoid client timeouts when using the new asynchronous linking service</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#known-issues_1","title":"Known issues","text":"<ul> <li>NEW: Filters in the samples table in Metadata Editor do not work for multi-value fields</li> <li>NEW: There is a known issue with streaming data export</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#new-restful-api-endpoints-for-asynchronous-linking","title":"New RESTful API endpoints for asynchronous linking","text":"<p>For creating links between objects:</p> <pre><code>POST\u200b /links\n</code></pre> <p>For finding links between objects:</p> <pre><code>GET /links\nPOST /links/get-batch\n</code></pre> <p>For deleting existing links:</p> <pre><code>DELETE /links\n</code></pre> <p>There are two additional endpoints that can be queried for information on data-types and possible links between them:</p> <pre><code>GET /data-types\nGET /data-types/links\n</code></pre>"},{"location":"usage/release-notes/v1.20-v1.29/#1271-11-aug-2020","title":"1.27.1 (11 Aug 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#fixed-issues_2","title":"Fixed issues","text":"<p>The status code returned when calling various endpoints that retrieve or delete a non-existing file will now return <code>404</code> rather than <code>400</code>. Various other small fixes have been made to the swagger documentation as well.</p>"},{"location":"usage/release-notes/v1.20-v1.29/#127-7-aug-2020","title":"1.27 (7 Aug 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#new-features-in-this-release","title":"New features in this release","text":"<ul> <li>GENE-TRANSCRIPT MAPPING: ODM can now work with gene-transcript mapping files. Users are able to load a mapping file, link it to expression matrices and search for genes and transcripts in mapping files to retrieve correspondingly mapped transcripts/genes.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#fixed-issues_3","title":"Fixed issues","text":"<ul> <li>The curation helper script has several improvements:<ul> <li>When a value is mapped to a new attribute name a copy is no longer kept under the old attribute name.</li> <li>Non-template attributes that have no values remaining after a mapping are removed.</li> <li>Multi-value mappings now work correctly.</li> <li>Whitespace values are no longer substituted, preventing a possible data corruption issue.</li> </ul> </li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#known-issues_2","title":"Known issues","text":"<ul> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#1261-15-jul-2020","title":"1.26.1 (15 Jul 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#fixed-issues_4","title":"Fixed issues","text":"<p>We fixed a bug in external dictionary synchronisation where new dictionaries were appended to existing ones in the system. Now the new dictionaries (containing changes compared to previous versions) update the existing ones. For dictionaries which have seen no changes, they are skipped by external dictionary service sync.</p>"},{"location":"usage/release-notes/v1.20-v1.29/#126-7-jul-2020","title":"1.26 (7 Jul 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#new-features-in-this-release_1","title":"New features in this release","text":"<ul> <li>FURTHER CURATION SCRIPT IMPROVEMENTS: The curation script now handles measurements which contain units properly and includes various bug fixes for edge cases. The script has also been generalised to remove customer-specific jargon or settings.</li> <li>PREVIEW OF LONG VALUES IN THE SAMPLE TABLE: In some studies which have long values in the sample metadata table, the values were previously truncated and for read-only users, there was no mechanism for the user to see the full value on the user interface. Now a user can simply double-click at a cell of the sample table and a preview box will appear to reveal the full value.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#known-issues_3","title":"Known issues","text":"<ul> <li>It is not possible to curate studies loaded by the Superloader from GEO.</li> <li>The curation script substitutes sample metadata values which are comprised of whitespaces only (i.e. resembling blank values) with terms from the dictionary in the <code>rule.json</code> file. This can potentially corrupt data because the substitution is not easily detected to be rectified.</li> <li>Regular (non-curator) users do not have rights to edit templates or change template assignment for a study, even if they have the \"Manage template\" permission box checked in the \"Users and organization\" application because being a curator is a pre-requisite of such rights.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#125-25-jun-2020","title":"1.25 (25 Jun 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#new-features-in-this-release_2","title":"New features in this release","text":"<ul> <li>NEW RELEASE NOTES LINK: We have added links to public release notes in the dashboard footer and left-hand-side dock menu, so users can refer to the notes for new features, fixed bugs and known bugs/limitations.</li> <li>CURATION SCRIPT IMPROVEMENTS: The python curation script has been updated to support use cases for curating multi-value fields in sample metadata (e.g. when one sample was treated by two different drugs in the same time point). We also took the opportunity to remove some hardcoded curation rules in the code which are no longer valid and rewrote many error or warning messages so they're more user-friendly and include actionable suggestions for fixing errors</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#fixed-issues_5","title":"Fixed issues","text":"<ul> <li>We have fixed a few bugs in the \"Superloader\" tool for loading data from NCBI Gene Expression Omnibus (GEO), so it's now possible to load again microarray studies (both metadata and indexed data, the latter subject to the files deposited at GEO), as well as sequencing studies (metadata only).</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#known-issues_4","title":"Known issues","text":"<ul> <li>NEW: It is not possible to curate studies loaded by superloader from GEO.</li> <li>NEW: The curation script currently throws an error and does not proceed with curation when it cannot detect the default template that's used implicitly by an API-loaded study (\"implicitly\" because the data-loading user did not specify the template for the study and the system falls back on to the default template). This does not lead to data corruption.</li> <li>NEW: The curation script substitutes sample metadata values which are comprised of whitespaces only (i.e. resembling blank values) with terms from the dictionary in the <code>rule.json</code> file. This can potentially corrupt data because the substitution is not easily detected to be rectified.</li> <li>Regular (non-curator) users do not have rights to edit templates or change template assignment for a study, even if they have the \"Manage template\" permission box checked in the \"Users and organization\" application because being a curator is a pre-requisite of such rights.</li> <li>Changes in the template-control status of an attribute are applied properly now due to the bug fix in release <code>1.23</code>, albeit sometimes with 20-30 seconds' delay, which in the curation workflow is sometimes not too noticeable and definitely not a blocker().</li> <li>As the result of using a different hashing algorithm to preserve the order of facets in the URL, Study Browser URLs bookmarked prior to the <code>1.23</code> release will no longer be valid.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#124-8-jun-2020","title":"1.24 (8 Jun 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#new-features-in-this-release_3","title":"New features in this release","text":"<ul> <li>ASYNCHRONOUS DATA LOADING API ENDPOINTS: A new extract-transform-load (ETL) service has been rolled out which allows for asynchronous import of study, samples and signals files to ODM via new RESTful API endpoints without HTTP time-outs even for large studies with thousands of samples. Using these endpoints, a user submits a data-loading request and receives a (job execution) identifier for the job that is processed in the background. The identifier can be used to query the job's status and retrieve the result when the request processing is completed. Please see the list of new endpoints at the end of these notes for this release, and the Swagger documentation for API usage.</li> <li>\"ACCESSIBLE TO ALL\" STUDY BROWSER FACET: Previously, studies shared with all members of an organisation could be found via the \"Shared with me\" facet in the study browser, which was not intuitive to our users. We have tweaked the logic of the facets so such studies can now be found under the facet called \"For all at &lt;organisation name&gt;\".</li> <li>ODM VERSION SHOWN ON THE FOOTER: Previously it was not possible to see the current ODM version number when a user logged on to ODM on the graphical user interface (GUI). This caused inconvenience when a user could not specify the ODM version used when trying to report an error or an observation about the GUI. From this release onward, the version number is shown in the Dashboard footer and left-hand-side shortcut dock.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#new-housekeepingadmin-features","title":"New housekeeping/admin features","text":"<ul> <li>CLICKHOUSE UPGRADE TO VERSION 20.4: This upgrade fixes a memory leak issue.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#fixed-issues_6","title":"Fixed issues","text":"<ul> <li>We fixed a labelling issue in the Study Browser's facet breadcrumb trail, where the facet \"Study status\" should have been called \"Curation Status\".</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#known-issues_5","title":"Known issues","text":"<p>(No new issues in this release)</p> <ul> <li>Regular (non-curator) users do not have rights to edit templates or change template assignment for a study, even if they have the \"Manage template\" permission box checked in the \"Users and organization\" application because being a curator is a pre-requisite of such rights.</li> <li>The Metadata Editor page shows \"infinite\" loading if the Bulk Replace operation is triggered on a new attribute that is introduced after applying a new template to the study (can be fixed by page refresh).</li> <li>Changes in the template-controlled status of an attribute are applied due to the bug fix (see Fixed Issue number 2 in the section above), albeit sometimes with 20-30 seconds' delay, which in the curation workflow is sometimes not too noticeable and definitely not a blocker.</li> <li>API user endpoints currently get staging (draft) version of data from any SPoT/HDAP using the API, instead of the last committed version, while searching by metadata. However, users will get the last committed version if retrieving SPoT/HDAP objects directly via the ID.</li> <li>Cursor pagination in the API works incorrectly for expression data.</li> </ul> <p>New RESTful API endpoints for loading and linking study, samples and expression/variant/flow cytometry signals:</p> <p>For loading study, samples and signals:</p> <pre><code>POST\u200b /import\u200b/study\nPOST \u200b/import\u200b/samples\nPOST \u200b/import\u200b/variant\nPOST \u200b/import\u200b/expression\nPOST \u200b/import\u200b/flow-cytometry\n</code></pre> <p>For linking signal groups to sample groups:</p> <pre><code>POST or DELETE \u200b/integration\u200b/link\u200b/expression\u200b/group\u200b/{sourceId}\u200b/to\u200b/sample\u200b/group\u200b/{targetId}\nPOST or DELETE\u00a0\u200b/integration\u200b/link\u200b/flow-cytometry\u200b/group\u200b/{sourceId}\u200b/to\u200b/sample\u200b/group\u200b/{targetId}\nPOST or DELETE\u00a0/integration/link/variant/group/{sourceId}/to/sample/group/{targetId}\n</code></pre> <p>For initiating, monitoring or stopping an asynchronous job:</p> <pre><code>GET \u200b/{jobExecId}\u200b/info\nGET \u200b/{jobExecId}\u200b/output\nPUT \u200b/{jobExecId}\u200b/restart\nPUT \u200b/{jobExecId}\u200b/stop\n</code></pre>"},{"location":"usage/release-notes/v1.20-v1.29/#123-27-may-2020","title":"1.23 (27 May 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#new-features-in-this-release_4","title":"New features in this release","text":"<ul> <li>MORE GRANULARITY IN TEMPLATE MANAGEMENT: Previously, users belonging to the \"curators\" group all have the rights to manage templates in an organisation. By \"manage\", we mean editing an existing template, duplicating an existing one, and also assigning a different template as the organisation's default. From this release onward, we delineate the roles of curators and template managers with more granularity. Curators will not be template managers, unless they have been granted the permission to by their organisation's administrator.</li> <li>NEW \"USERS AND ORGANIZATION\" APPLICATION: Previously known as \"Manage Users\", we took the opportunity to update its look-and-feel and improve its functionalities while adding the new \"Manage template\" permission granularity. Key improvements include clearly indicating the administrators in the organisation and adding a built-in search bar so users can search for a colleague by name or email address. Please also note that from this release onward, an organisational administrator is also prohibited from revoking his/her own admin rights, to ensure at least one other administrator in the organisation is aware of and approves this resignation.</li> <li>STUDY BROWSER'S APPLIED FILTERS DISPLAYED AS INDIVIDUALLY REMOVABLE TAGS: This is an enhancement of the Study Browser search experience. Facets selected by the user will now appear as tags above the search results, showing a trail of the facet options. Each filter option can be conveniently removed via the tags as if the user has unchecked the facet option. The Study Browser URL contains a hash that remembers the facets and the order they're applied, so a user can share the URL with a colleague to recreate the same set of search criteria. Please note: as the result of using a different hashing algorithm to preserve the order of facets in the URL, Study Browser URLs bookmarked prior to this release will no longer be valid.</li> <li>SWIFTSTACK INTEGRATION: For customers who use Swiftstack to store data that is later ingested into Genestack, in order for Genestack to access this data, temporary (or pre-signed) URLs can be generated before feeding them into Genestack. For the temporary URLs to be generated, a functionality was implemented for a technical user to access the shared folder on Swiftstack.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#new-housekeepingadmin-features-in-this-release","title":"New housekeeping/admin features in this release","text":"<ul> <li>NEW STATUS FLAG TO TRACK EXPRESSION DATA INDEXING: As the volume and complexity of expression data grow, we have improved ODM's error-handling when indexing expression data. A status flag is now set in the ODM\u2019s database, with the \u201cfailed\u201d status reflecting internal exceptions from the expression data indexer during indexing, while the status \u201cok\u201d marks the end of indexing (if process is completed without errors). An organisation's administrator or system admin can use this flag to quickly identify expression studies with corrupted indices and re-index them in a targeted way, without having to wipe the whole index and reindex all data from scratch.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#fixed-issues_7","title":"Fixed issues","text":"<ul> <li>We identified a general bug that prevented many graphical user interface applications from reusing resources and caching data properly, resulting in performance penalties. We have fixed this bug and overall the interface is more responsive. The most noticeable improvement is in the Metadata Editor application.</li> <li>For a template that is in active use (i.e. applied to a study), if a sample attribute is removed from the template, we expect the attribute to be kept in the study and shown as a non-template-controlled field. This behaviour was broken, but fixed in this release.</li> <li>Improved SAML error messages: the system now correctly parses the status of the IdP response and displays more user-friendly error messages.</li> <li>For MEX-format single-cell data, <code>NaN</code> values in <code>.mtx</code> expression matrices used to result in errors which terminate the data indexing process. We have fixed this now so <code>NaN</code> or any non-numeric values in .mtx files will be skipped by the system, and the frequency of such skipped entries is recorded in a log file for debugging purposes.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#known-issues_6","title":"Known issues","text":"<ul> <li>NEW: regular (non-curator) users do not have rights to edit templates or change template assignment for a study, even if they have the \"Manage template\" permission box checked in the \"Users and organization\" application because being a curator is a pre-requisite of such rights.</li> <li>NEW: The Metadata Editor page shows \"infinite\" loading if the Bulk Replace operation is triggered on a new attribute that is introduced after applying a new template to the study (can be fixed by page refresh).</li> <li>NEW: Changes in the template-controlled status of an attribute are applied due to the bug fix (see Fixed Issue number 2 in the section above), albeit sometimes with 20-30 seconds' delay, which in the curation workflow is sometimes not too noticeable and definitely not a blocker.</li> <li>NEW: As the result of using a different hashing algorithm to preserve the order of facets in the URL, Study Browser URLs bookmarked prior to this release will no longer be valid.</li> <li>API user endpoints currently get staging (draft) version of data from any SPoT/HDAP using the API, instead of the last committed version, while searching by metadata. However, users will get the last committed version if retrieving SPoT/HDAP objects directly via the ID.</li> <li>Cursor pagination in the API works incorrectly for expression data.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#122-7-may-2020","title":"1.22 (7 May 2020)","text":""},{"location":"usage/release-notes/v1.20-v1.29/#new-features-in-this-release_5","title":"New features in this release","text":"<ul> <li>NEW NAVIGATION PANEL IN \"MANGE GROUPS\" APP: For organisations with many groups or groups with many members, the app's page can get really long and it was cumbersome to scroll precisely to the group of interest. The new navigation panel solves this by allowing users to jump to the group needed.</li> <li>VCF.ZIP SUPPORT: The vcf indexer used to work with only <code>vcf.gz</code> files. From this release onward, we start supporting zip-compressed vcf files too.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#fixed-issues_8","title":"Fixed issues","text":"<ul> <li>In Metadata Editor's bulk replace feature, values in boolean fields can't be replaced or left blank in some cases. This is now fixed.</li> <li>In Metadata Editor's bulk replace feature, replacing blank values sometimes failed. In addition, sample counts for blank values inside the bulk replace dialogue were often miscalculated. These bugs related to blank values have been fixed.</li> <li>There was an issue with URLs pointing to ODM pages returning an error during opening if they end with a <code>/</code> character. The cause of this error was not obvious to the user (even though it was relatively easy to remove the slash). This is now fixed so the ending slash wouldn't hinder links being opened.</li> </ul>"},{"location":"usage/release-notes/v1.20-v1.29/#known-issues_7","title":"Known issues","text":"<ul> <li>API user endpoints currently get staging (draft) version of data from any SPoT/HDAP using the API, instead of the last committed version, while searching by metadata. However, users will get the last committed version if retrieving SPoT/HDAP objects directly via the ID.</li> <li>Cursor pagination in the API works incorrectly for expression data.</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/","title":"Release notes","text":""},{"location":"usage/release-notes/v1.30-v1.39/#139-10-august-2021","title":"1.39 (10 August 2021)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release","title":"New/updated features in this release","text":"<ul> <li>Metadata Editor: The special 'Not applicable' and 'Not reported' values are now available in autocomplete suggestions</li> <li>Metadata Editor: When filters are being recalculated there is now a loading indicator</li> <li>Metadata Editor: S3 links are clickable in the non-curator view</li> <li>A new configuration parameter <code>additionalJwksUris</code> was introduced to the OAuth provider properties file. This allows the user to specify a list of additional JWKS URIs that can be used for checking token signatures.</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#api-changes","title":"API changes","text":"<ul> <li>Values accepted by the <code>returnedMetadataFields</code> parameter (for all endpoints that can return metadata) have changed (previous values still currently work for backwards compatibility). The values are now:<ul> <li><code>minimal_data</code> - return only metadata in accordance with the default template</li> <li><code>extended_data_included</code> (previously: <code>template</code>) - return metadata in accordance with the applied template</li> <li><code>original_data_included</code> (previously: <code>all</code>) - return all metadata attributes</li> </ul> </li> <li>Endpoints returning dictionary (controlled vocabulary) terms can now also return the identifier for that dictionary term (by supplying the value <code>term_id</code> to the <code>include</code> parameter).</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues","title":"Fixed issues","text":"<ul> <li>Metadata Editor: After importing new samples from a spreadsheet the values are available to replace in the bulk replace dialog right away without needing to refresh the page</li> <li>Metadata Editor: In the non-curator view it is now possible to filter samples by values with the type <code>date</code>.</li> <li>The API behaviour for xrefsets endpoints was improved:<ul> <li>The endpoints <code>POST /xrefsets</code> and <code>DELETE \u200b/xrefsets\u200b/{id}</code> returns <code>403 \u201cNot enough permissions to work with the xrefset\u201d</code> if a user is not a member of the Curator Group.</li> <li>The endpoint <code>GET /xrefsets/{id}/metadata</code> returns <code>400</code> Bad request if a user passes invalid object\u2019s ID (anything apart from Genestack accession).</li> </ul> </li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#138-28-june-2021","title":"1.38 (28 June 2021)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release_1","title":"New/updated features in this release","text":"<ul> <li>The Metadata Editor has several new features:<ul> <li>Absence of values is indicated with a specific <code>No value</code> in italics</li> <li>Columns are resizable</li> <li>We have introduced special <code>Not applicable</code> and <code>Not reported</code> values that are always valid regardless of template rules</li> <li>Autocomplete suggestions for <code>Not applicable</code> and <code>Not reported</code> values have been added to the bulk replace dialog</li> <li>The bulk replacement dialog will now reveal full values when you hover over them</li> <li>Removed explicit manual pagination from metadata table. Users can scroll samples table infinitely</li> </ul> </li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues_1","title":"Fixed issues","text":"<ul> <li>Fixed an issue when a user without curator permissions has no way to explore an applied template from the Metadata Editor</li> <li>Fixed an issue with removing filters when no samples match them</li> <li>A bug in omics/expression/data after deleting a xref mapping file was fixed</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues_1","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#137-25-may-2021","title":"1.37 (25 May 2021)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release_2","title":"New/updated features in this release","text":"<ul> <li>The Users and Permissions page has been updated with a new look and feel. You can use the contextual menu to deactivate/activate particular users</li> <li>Error logs/code/other text have improved security</li> <li>The URL of the \u201cGroups\u201d page has changed to <code>/frontend/endpoint/application/run/genestack/web/groups</code></li> <li>Instances with Arvados integration: Arvados hosts are shown in user profiles, and can be clicked on to open Arvados Workbench</li> <li>Instances with Arvados integration: Arvados error messages have been improved</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues_2","title":"Fixed issues","text":"<ul> <li>Instances with Arvados integration: A problem with importing studies via the Arvados importer GUI has been fixed.</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues_2","title":"Known issues","text":"<ul> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#136-27-april-2021","title":"1.36 (27 April 2021)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release_3","title":"New/updated features in this release","text":"<ul> <li>Users have the option to expand the Bulk Replace dialogue so the values to be replaced are not truncated</li> <li>Swagger help page descriptions have been improved</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues_3","title":"Fixed issues","text":"<ul> <li>Swagger descriptions of some endpoint page limits have been corrected</li> <li>Sorting using the cursor on omics endpoints now works correctly</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues_3","title":"Known issues","text":"<ul> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#135-30-march-2021","title":"1.35 (30 March 2021)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release_4","title":"New/updated features in this release","text":"<ul> <li>All user accounts will now appear in the users list, including technical superuser accounts</li> <li>The organization name will no longer be displayed in the interfaces</li> <li>The option to sign in with Okta is now available</li> <li>Several pages interfaces have been moved to a new framework</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#api-changes_1","title":"API changes","text":"<ul> <li>Swagger help page descriptions have been improved</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues_4","title":"Fixed issues","text":"<ul> <li>Filters now work for multi-values in the metadata editor</li> <li>Bulk-replace operations in the metadata editor now occur in parallel (replacing <code>A,B</code> with <code>A-&gt;B</code> and <code>B-&gt;C</code> will now result in <code>B,C</code> not <code>C,C</code>)</li> <li>Corrected error messages for permissions related failures</li> <li>Gene dictionaries now initialise correctly</li> <li><code>GET omics/samples</code> no longer fails with the error <code>incorrect cursor format</code></li> <li>Cursor pagination works correctly in omics/samples with no filters</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues_4","title":"Known issues","text":"<ul> <li>It is not possible to import public studies since the superloader module has been removed. This functionality will be considered in the future</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#134-5-march-2021","title":"1.34 (5 March 2021)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release_5","title":"New/updated features in this release","text":"<ul> <li>The URL for the Study Browser has been changed</li> <li>Imported templates and dictionaries are shared with everyone by default</li> <li>The default template can be edited - this change requires the default template be selected again when <code>1.34</code> is first deployed.</li> <li>The <code>import_ODM_data</code> script now returns the jobExecutionIdentifier to users so imports can be monitors</li> <li>Organization properties have been moved to a configuration file</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#api-changes_2","title":"API changes","text":"<ul> <li>Depreciated API endpoints have been removed</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues_5","title":"Fixed issues","text":"<ul> <li>Fixed an error with xref mapping</li> <li>Fixed an issue deleting studies via the <code>studyCurator</code> endpoints</li> <li>Fixed an issue causing invalid sample filter counts when there are invalid field values</li> <li>Improved error descriptions for the helper script <code>create_users.py</code></li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues_5","title":"Known issues","text":"<ul> <li>It is not possible to import public studies since the superloader module has been removed. This functionality will be considered in the future</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>Filters in the samples table in Metadata Editor do not work for multi-value fields</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#133-27-jan-2021","title":"1.33 (27 Jan 2021)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release_6","title":"New/updated features in this release","text":"<ul> <li>NEW METADATA OBJECT TYPES: Libraries and Preparations have been added as additional types of objects which users can import, link, edit and query. These optional single sources of truth contain information about how samples for transcriptomics and proteomics studies respectively have been prepared, and are supported with the usual suite of validation and curation tools in ODM</li> <li>NEW ENDPOINTS: <code>/libraries</code> and <code>/preparations</code> (which can be found under <code>libraryUser/Curator</code> and <code>preparationUser/Curator</code> in swagger) have been added to support importing, linking, editing and querying libraries and preparations</li> <li>Gene-transcript mapping has been generalised to cross-reference mapping and endpoints have been renamed <code>/xrefsets</code>, which can be found under the reference-data section in swagger. These endpoints have also been extended for more flexible functionality</li> <li>There is a new user permission <code>CONFIGURE_FACETS</code>. Users with this permission can configure the facets that are displayed in the Study Browser</li> <li>The module for importing public studies has been removed</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues_6","title":"Fixed issues","text":"<ul> <li>Fixed some issues and issue help text for the /xrefsets (was gene-transcript mapping) endpoints</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues_6","title":"Known issues","text":"<ul> <li>NEW: It is not possible to import public studies since the superloader module has been removed. This functionality will be considered in the future</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>Filters in the samples table in Metadata Editor do not work for multi-value fields</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#132-30-dec-2020","title":"1.32 (30 Dec 2020)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release_7","title":"New/updated features in this release","text":"<ul> <li>The group roles have been simplified to just group administrator and sharing member</li> <li>The auto-complete dropdown no longer displays <code>searching...</code>, it shows auto-complete matches or an explicit <code>search for &lt;input value&gt;</code> option instead</li> <li>Starting ODM for the first time or when no data is currently available now displays a more user-friendly page</li> <li>Facet value sorting in the Study Browser has been improved to prevent ordering switching too much when selecting multiple data types</li> <li>Adding new files to a study now automatically shares them with the same permissions as the study</li> <li>New files added to a study automatically have the study template applied to them</li> <li>The Python client (used by some helper scripts) is now based on Python 3</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues_7","title":"Fixed issues","text":"<ul> <li>Additional improvements have been made to asynchronous data loading services (ETL), in particular when loading large expression files</li> <li>Improved error messages when attempting to link objects with no matching Sample Source IDs in the samples table</li> <li>Performance in the Study Browser has been improved when there are lots of different facet values</li> <li>The share studies option now forces selection from existing groups rather than free text</li> <li>Copying dictionary names in the Template Editor now works correctly</li> <li>Search text in the Groups application is preserved when making changes to a user\u2019s role</li> <li>Fixed an issue exporting expression data that came from an S3 source</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#api-changes_3","title":"API changes","text":"<ul> <li>Added a new parameter <code>returnedMetadataFields</code> to integration endpoints. This parameter controls the amount of metadata that is returned from integration queries. By default, curator endpoints return all available metadata and user endpoints return metadata only for template fields.</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues_7","title":"Known issues","text":"<ul> <li>NEW: The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>There are currently some issues loading data from GEO</li> <li>Filters in the samples table in Metadata Editor do not work for multi-value fields</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#131-11-nov-2020","title":"1.31 (11 Nov 2020)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release_8","title":"New/updated features in this release","text":"<ul> <li>Added a user permission <code>MANAGE_ORGANIZATION</code> which can be toggled in the Users and Organization application. This replaces the previous (fixed) organization administrator role.</li> <li>API endpoints for linking (<code>POST /integration/link/*</code>) now better handle situations where a user is importing data for some samples but not all.</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues_8","title":"Fixed issues","text":"<ul> <li>Several improvements have been made to asynchronous data loading services (ETL)</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues_8","title":"Known issues","text":"<ul> <li>NEW: There are currently some issues loading data from GEO</li> <li>Filters in the samples table in Metadata Editor do not work for multi-value fields</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#130-16-oct-2020","title":"1.30 (16 Oct 2020)","text":""},{"location":"usage/release-notes/v1.30-v1.39/#newupdated-features-in-this-release_9","title":"New/updated features in this release","text":"<ul> <li>Variant API queries can now be done against multiple variants</li> <li>A template can now be chosen as the default template through the GUI</li> <li>Pagination of query results for the <code>omics/*/data</code> endpoints now uses the cursor parameter instead of <code>pageoffset</code>. Results returned include a <code>cursor</code> tag. Repeat your query and supply this tag to the cursor parameter to obtain the next page of results and a new cursor tag. When no more results are available the return will be empty.</li> <li><code>Pageoffset</code> pagination is now depreciated for <code>omics/*/data</code> endpoints</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#fixed-issues_9","title":"Fixed issues","text":"<ul> <li>Fixed an issue preventing non-curator users who had manage templates permissions from exploring templates via the Metadata Editor</li> </ul>"},{"location":"usage/release-notes/v1.30-v1.39/#known-issues_9","title":"Known issues","text":"<ul> <li>Filters in the samples table in Metadata Editor do not work for multi-value fields</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/","title":"Release notes","text":""},{"location":"usage/release-notes/v1.40-v1.49/#149","title":"1.49","text":""},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release","title":"New/updated features in this release","text":"<ul> <li>The ability to load files to ODM from a local machine with installed ODM via NFS is added. To load files to ODM, users should use Job API endpoints for async loading, e.g., <code>POST /import/expression</code> with <code>\"source\": \"LOCAL\"</code>. Loading mapping files from a local machine via <code>POST /xrefsets</code> is not supported.</li> <li>The <code>main()</code> function is added to the <code>import_ODM_data.py</code> script.</li> <li>Dictionaries without any term can be loaded to ODM. And if such a dictionary is assigned to an attribute in the template, this attribute is treated as a free text attribute in Metadata Editor. Any text that the user enters is valid.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues","title":"Fixed issues","text":"<ul> <li>Fixed: Sometimes, a wrong sample count is displayed in the Study Browser after importing a study to ODM.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#148","title":"1.48","text":""},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release_1","title":"New/updated features in this release","text":"<ul> <li>API endpoints for working with user accounts have been introduced, all endpoints require the \"Manage organisation\" permission (user should be Admin in ODM):<ul> <li><code>GET /groups</code>: the endpoint returns a list of non-deleted user groups in which the user is a member of the group. Users can be filtered by their attributes, e.g. by <code>displayName</code>;</li> <li>User accounts can be created and updated using <code>POST /users</code> endpoint;</li> <li>Attributes of a specific user account can be updated by <code>PATCH /users/{id}</code> endpoint.</li> </ul> </li> <li>Improvements in the Metadata Editor:<ul> <li>Attribute description and its data type are shown in the attribute menu and the bulk replace dialogue;</li> <li>Share-study dialogue was redesigned. When a user shares a study with a new group, the user can see a list of the groups with which this study has already been shared.</li> </ul> </li> <li>A new permission \u201cManage groups\u201d was implemented, it allows to retrieve all user groups.</li> <li>Improvements in API:<ul> <li>Performance is improved for the cases of a significant amount of patch requests (with disabled metadata versioning on the instance);</li> <li>Optimization of omics query results in faster queries, and the system stability (less memory per processor is used, etc.).</li> </ul> </li> <li>The code quality and maintainability of the import_ODM_data.py python script for data loading to ODM have been improved:<ul> <li>All argument keys use dashes consistently, e.g. <code>--mapping-file</code>. Arguments with underscores are still supported, e.g. <code>--mapping_file</code>;</li> <li>User can load large files with preparations and libraries (&gt;10 000 rows) via the <code>Import_ODM_data.py</code> script since the script uses async API for data loading.</li> </ul> </li> <li>The documentation covering <code>update_templates.py</code> script has been updated.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues_1","title":"Fixed issues","text":"<ul> <li>Fixed: querying signal runs via <code>GET /expression/runs/by/group/{id}</code> returns incorrect \"total\" in pagination info.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues_1","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#147","title":"1.47","text":""},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release_2","title":"New/updated features in this release","text":"<ul> <li>The \"Description\" field is added for attributes in Template Editor. The field can be used to store a brief explanation of what each attribute was intended for, examples of values, etc. The maximum length of the description is 500 characters.</li> <li>Attribute descriptions, which provide a brief explanation of what each attribute was intended for, examples of values, etc., are added in Metadata Editor. A description of each attribute can be edited in the study template.</li> <li>The \"Description\" attribute is supported in the python script for loading templates.</li> <li>Curate libraries and preparations metadata using the curation script.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues_2","title":"Fixed issues","text":"<ul> <li>Fixed: dates are displayed in milliseconds in the view mode of Metadata (e.g., <code>\"1638448612812\"</code> instead of <code>\"December 2, 2021\"</code>).</li> <li>Fixed: when a new template is created using the Duplicate function of the Template Editor, the page does not indicate whether the new template has been generated.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues_2","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#146","title":"1.46","text":""},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release_3","title":"New/updated features in this release","text":"<ul> <li>When the user switches between editing and viewing modes in the Metadata Editor, the selected filters are saved (there is no need to choose and apply them again).</li> <li>Visual distinction highlight of template vs. non-template attributes is added to all tabs of the Metadata Editor.</li> <li>More effortless study curation when changing the applied template or applying a new template that causes a change in the attribute data types. Previously: if e.g., the <code>age</code> field is a <code>string</code> attribute, it is changed to become an <code>integer</code> attribute in a new applied template. This attribute's previously valid values were marked as <code>invalid</code>, so the user had to edit each value.     Currently: the user can call a mass conversion of the value types according to the applied template.     The following type conversions are supported: <code>Text</code> -&gt; <code>Integer</code>, <code>Text</code> -&gt; <code>Decimal</code>.</li> <li>The user confirmation request was added to the Template Editor for the attribute removal from the template. It avoids accidental removal of the attribute or changing the validation rules used in studies.</li> <li>MySQL version has been upgraded to <code>8.0.28</code> to avoid vulnerabilities in the previous version.</li> <li>ClickHouse is updated from <code>21.8</code> to <code>21.12</code>. The ClickHouse logs are more straightforward. Investigating ClickHouse problems has become easier.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues_3","title":"Fixed issues","text":"<ul> <li>Fixed: the application returns an error when adding a new facet in the \"Configure facets\" application with underscores in the name (e.g., <code>Study_Type</code> instead of <code>StudyType</code>), and saving the changes.</li> <li>Fixed: an incorrect number is displayed in the counter on the Samples tab in Metadata Editor after applying filters.</li> <li>Fixed: switching from the edit mode to the view mode causes an error \"Page unresponsive\" while working with a study with more than 10k+ samples in Metadata Editor.</li> <li>Fixed: The filters in the Metadata Editor were not updated while the user was editing the sample attributes. E.g., the user filters samples by <code>Disease = Asthma</code>; updates the value of one of the attributes from <code>Asthma</code> to <code>Cancer</code> and does not publish changes; then the sample is continued to be returned in filters by <code>Disease = Asthma</code>.</li> <li>Fixed: the user needs to refresh the page in the Metadata Editor to publish the changes.</li> <li>Fixed: The user receives an error message when reassigning an attribute to a column with integer values on the Samples tab in Metadata Editor.</li> <li>Fixed: Obsolete dictionaries were not highlighted in red in the Template Editor application; the user could have mistakenly selected an outdated dictionary for an attribute.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues_3","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#145","title":"1.45","text":""},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release_4","title":"New/updated features in this release","text":"<ul> <li>Solr <code>8.11.1</code> version is updated to resolve the <code>log4j</code> vulnerability.</li> <li> <p>Full-text and facet search for studies via API endpoint <code>POST /integration/fulltext/search/studies</code>. The endpoint allows searching for studies by study metadata and all linked objects' metadata (e.g., samples, libraries, preparations, omics metadata). Examples:</p> <p>a) find all studies where the term \"cancer\" occurs in the data, e.g., in samples or the study description;</p> <p>b) find all studies by a specific facet <code>\"Disease\" = \"Asthma\"</code> (the endpoint performs search only across facets defined in the \"Configure facets \"application).</p> <p>The endpoint returns:</p> <ul> <li>a list of studies with the metadata summary;</li> <li>a list of facet objects with counts (the same list of facets shown in the \"Study Browser\" application).</li> </ul> </li> <li> <p>Asynchronous loading of files with \"preparation\" information via API endpoint <code>POST /import/preparations</code> to upload files with more than 10k rows.</p> </li> <li>The performance of filters in Metadata Editor in edit mode was improved (1.5 times faster processing on the Genestack test environment). The exact time difference depends on the instance settings and the connection provider.</li> <li>Ability to copy values and reassign attributes for both template and non-template attributes in Metadata Editor.</li> <li>The <code>import_ODM_data</code> python script now supports versions of Omics data files. Thus, the user can upload a new omics data file to an existing study using the \"import_ODM_data\" python script as the next version of the previously uploaded file. The solution has limitations described in the python script documentation.</li> <li>Synchronous uploading performance of samples via the API endpoint <code>POST /samples</code> was improved (2.7 times faster processing on the Genestack test environment). The exact time difference depends on the instance settings and the connection provider. Now optional \"Warning\" attribute with the results of sample validation for the applied template is not returned in the response body.</li> <li>The deprecated endpoint for loading cross-reference (xref) mapping files <code>POST \u200b/import\u200b/transcript-mapping</code> method has been removed; the endpoint call returns an error. For cross-reference mapping files loading user can use <code>POST /xrefsets</code>.</li> <li>The \"View Logs\" button is removed from the Export page.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues_4","title":"Fixed issues","text":"<ul> <li>Breaking changes! The method <code>get_parents_by_study</code> was renamed to <code>get_groups_by_study</code> in Python and R SDK. If your application uses the methods <code>get_parents_by_study</code>, rename all the method usages to <code>get_groups_by_study</code>. If your application does not use R or Python SDK, no changes are required.</li> <li>If the mapping file contains duplicates, the endpoint loads only unique rows. A warning regarding duplicates is returned in the response body, e.g., \"The loaded file includes three duplicate rows that were skipped\". Previously, when the user loaded mapping files with duplicate rows via <code>POST /xrefsets</code>, the endpoint stopped the file loading on the first duplicate and did not return the warning message. The user did not know whether the entire file was loaded or not.</li> <li>When a user applies another template to a study in Metadata Editor, the new validation rules are immediately applied. It allows the user to see the actual data, the actual set of required attributes, and the actual status of the data validation. Previously, the user needed to refresh the page to enable it.</li> <li>Fixed: when a user adds and removes the multi-value field in Study Metadata, the error is returned.</li> <li>R SDK documentation is improved:<ul> <li>An example \"include \"parameter value is added to the description.</li> <li>Clients receive an exception when passing unknown parameters in functions.</li> </ul> </li> <li>Fixed: API endpoints for removing links between objects return code <code>204</code> if the specified object of a wrong type or there was no link between objects. The endpoints return <code>404</code> with a message corresponding to the case. Affected <code>DELETE</code> endpoints:<ul> <li><code>/integration/link/sample/{sourceId}/to/study/{targetId}</code></li> <li><code>/integration/link/sample/group/{sourceId}/to/study/{targetId}</code></li> <li><code>/integration/link/library/{sourceId}/to/sample/{targetId}</code></li> <li><code>/integration/link/library/group/{sourceId}/to/sample/group/{targetId}</code></li> <li><code>/integration/link/preparation/{sourceId}/to/sample/{targetId}</code></li> <li><code>/integration/link/preparation/group/{sourceId}/to/sample/group/{targetId}</code></li> </ul> </li> <li>Fixed: the swagger page does not become unresponsive when the user calls the endpoint <code>GET /sampleCurator/samples</code> without specified <code>pageLimit</code>, and there are more than 2000 samples.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues_4","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#144","title":"1.44","text":"<p>Deployment note</p> <p>Versions from <code>1.42</code> onwards use a new schema for core ClickHouse tables. The previously released version <code>1.41</code> includes migration scripts so deployment of <code>1.41</code> and completion of this migration job must have taken place before deploying any version from <code>1.42</code> onwards.</p>"},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release_5","title":"New/updated features in this release","text":"<ul> <li>Filters in the Metadata Editor are now applied faster.</li> <li>The Metadata Editor allows scrolling across the table.</li> <li>Ontology-aware search for RDF-formatted ontologies: When using the search bar in the Study Browser exact and related synonyms are added to the search query by default (where the user\u2019s query matches a term from an ontology). Users can also extend the results of a query by toggling inclusion of all child (descending) terms.</li> <li>Study Browser results summaries now include metadata from these additional fields: <code>Data Species</code>, <code>Species Name</code>, <code>Sample Type</code> and <code>Disease Status</code>.</li> <li>Users can load libraries data objects asynchronously via a new endpoint <code>POST /import/libraries</code>. The endpoint returns a <code>jobExecId</code>, and the results can be checked via the Job operations endpoint.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues_5","title":"Fixed issues","text":"<ul> <li>Critical security vulnerability was fixed in <code>log4j</code>.</li> <li>Fixed exporting omics data where metadata versioning feature is enabled.</li> <li>Edit mode in the Metadata Editor no longer causes timeouts with large (50,000) samples tables.</li> <li>Reassigning attribute now correctly deletes the source column from view mode as well as from edit mode in the Metadata Editor.</li> <li>Metadata Editor now has correct filters descriptions when values are updated.</li> <li>Links are recognized and clickable in the view mode of the study metadata tab.</li> <li>Users now see the correct facets values for bulk replace after discarding changes.</li> <li>The correct number of available samples is shown after filtering.</li> <li>Incorrect use of the template was fixed for Bulk replace in Library/Preparation metadata.</li> <li>Fixed a problem with unpublished versions after turning on metadata versioning feature.</li> <li>Curation script works for Variant, Expression and Flow Cytometry metadata as well as for tabs <code>Study</code> and <code>Samples</code></li> <li>Loading of <code>vcf</code> files with values <code>nan</code> was fixed</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues_5","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#143","title":"1.43","text":"<p>Deployment note</p> <p>Versions from <code>1.42</code> onwards use a new schema for core ClickHouse tables. The previously released version <code>1.41</code> includes migration scripts so deployment of <code>1.41</code> and completion of this migration job must have taken place before deploying any version from <code>1.42</code> onwards.</p>"},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release_6","title":"New/updated features in this release","text":"<ul> <li>Full text search in the Study Browser now supports ontology expansion - if a search term matches a term from an ontology in RDF format then it is possible to extend the query to include child terms (those with the <code>subClassOf</code> property), up to a limit of 30,000 child terms (and synonyms).</li> <li>Full text search now automatically includes exact and related synonyms (<code>hasRelatedSynonym</code> or <code>hasExactSynonym</code> in the RDF)</li> <li>There is a new <code>roundDigits</code> request parameter for the /streamed-data endpoint. By default <code>roundDigits = 4</code></li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues_6","title":"Fixed issues","text":"<ul> <li>Metadata Editor: Renaming a study via the contextual menu now creates a new version (if metadata versioning is enabled).</li> <li>Users who singed in using SSO (<code>OAuth2</code>) now can re-sign in via one click again after being logged out due to security reasons.</li> <li>Now it is possible to undo (ctrl+z) and redo (ctrl+shift+z) manual changes to metadata.</li> <li>The metadata validation summary now correctly reports valid metadata when all metadata is valid.</li> <li><code>UserEndpoint</code> APIs return latest draft (staging) versions of signals metadata when versioning feature is disabled, ensuring users get the latest version of the data.</li> <li>Swagger endpoints have had some extraneous descriptions removed.</li> <li>Swagger description for <code>GET /omics/expression/streamed-data</code> has been improved.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues_6","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#142","title":"1.42","text":"<p>Deployment note</p> <p>Versions from <code>1.42</code> onwards use a new schema for core ClickHouse tables. The previously released version <code>1.41</code> includes migration scripts so deployment of <code>1.41</code> and completion of this migration job must have taken place before deploying any version from <code>1.42</code> onwards.</p>"},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release_7","title":"New/updated features in this release","text":"<ul> <li>Metadata versioning is available as a beta feature. To enable it see the administration guide. By default it is not enabled.</li> <li>The <code>POST /task/publish-versions</code> API endpoint was added to support metadata versioning.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues_7","title":"Fixed issues","text":"<ul> <li>Metadata Editor: Applying a new template is now reflected immediately without needing a page refresh.</li> <li>Metadata Editor: Copying/previewing sample accessions now work correctly with pagination.</li> <li>A bug with session tokens after a server restart has been fixed.</li> <li>Adding samples via <code>POST /integration\u200b/link\u200b/sample\u200b/group\u200b/\u2026\u200b/to\u200b/study\u200b/\u2026</code> now correctly shares these samples with the same permissions as the study being added to.</li> <li>The Uberon ontology now successfully initiates on instances with HTTP(S) proxies.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues_7","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies.</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#141","title":"1.41","text":"<p>Deployment note</p> <p>This release contains a periodic job which automatically migrates core ClickHouse tables (<code>ExpressionDataByRun</code>, <code>ExpressionDataByGene</code>) to a new schema. It is mandatory to let this job finish before installing future releases (<code>1.42</code> etc.) as they will not support the old schema. The job is finished when the backend logs contain the messages: <code>Migration of data for table {} finished</code>, where <code>{}</code> is <code>ExpressionDataByRun</code> and <code>ExpressionDataByGene</code>.</p>"},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release_8","title":"New/updated features in this release","text":"<ul> <li>Minor dashboard text changes</li> <li>The Template Editor URL has changed to a Base URL of: <code>frontend/endpoint/application/run/genestack/web/templates</code>     Redirects are in place for the previous URL.</li> <li>Improved use of server resources (disk space in particular)</li> <li>Improved performance of omics data queries</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues_8","title":"Fixed issues","text":"<ul> <li>Metadata Editor: Fixed an issue filtering by invalid values works for Integer/Date data types. Now users can use date/integer values for filtering even if they are invalid according to the template</li> <li>Metadata Editor: Dictionary terms are now correctly highlighted after changing template.</li> <li>An Expression data query performance degradation bug has been fixed</li> <li>Patch API calls now work on large sample numbers</li> <li>Omics queries: Filtering of variants by INFO fields in text format is working now, e.g. <code>vxQuery = info_VT=INDEL</code></li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues_8","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#140","title":"1.40","text":"<p>Customers should update their SSL settings to use a <code>2048-bit</code> or greater DH cipher</p>"},{"location":"usage/release-notes/v1.40-v1.49/#newupdated-features-in-this-release_9","title":"New/updated features in this release","text":"<ul> <li>Study Browser: Added a syntax cheatsheet that describes how to use advanced full-text search capabilities</li> <li>Metadata Editor: Added a new export button to export all data/metadata of a study</li> <li>Export: Exports now include a readme detailing the files contained in the archive</li> <li>API endpoints: A <code>400</code> http code is now returned when an unknown parameter is supplied to any endpoint</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#fixed-issues_9","title":"Fixed issues","text":"<ul> <li>Metadata Editor: Fixed an issue editing fields at the bottom of the window</li> <li>Study browser: Fixed saved bookmark icons</li> <li>Omics data files are exported with the same extensions that they were imported with</li> </ul>"},{"location":"usage/release-notes/v1.40-v1.49/#known-issues_9","title":"Known issues","text":"<ul> <li>Metadata Editor: There is no automatic formatting of numeric values, they will be displayed as strings \u2013 aligned to left instead of right.</li> <li>The study browser may continue to show and search facet values from objects that have been unlinked from studies</li> <li>The curation helper script doesn't work for Variant, Expression and Flow Cytometry objects, only for studies and samples</li> </ul>"},{"location":"usage/release-notes/v1.50-v1.59/","title":"Release notes","text":"<p>Target users</p> <p>Curators - users who add new data into ODM and are responsible for the data harmonization and curation. That includes creating and defining metadata templates, mapping metadata and temples, and data updates.</p> <p>Researchers - users who access ODM to identify a batch of data suitable for further research and analysis. That includes search, data browsing and export.</p> <p>Advanced - users who can utilize advanced API functionalities for user management and data management.</p> <p>Admins - users who manage organization in ODM, its user and groups.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#156-open-data-manager-2024-february-release","title":"1.56 Open Data Manager 2024 February Release","text":""},{"location":"usage/release-notes/v1.50-v1.59/#new-features","title":"New Features","text":"<ul> <li>[Advanced] Usage Tracking: this feature allows to collect metrics and statistics organised in dashboards on Genestack side. Information for particular instance can be requested from Genestack. Currently available metrics are:<ul> <li>Number of users with \u201cActivated\u201d status.</li> <li>Number of API calls broken down by API labels.</li> <li>Average length of UI sessions.</li> <li>Number of Studies.</li> <li>Number of metadata objects and groups for Samples, Libraries, and Preparations.</li> <li>Number of data objects broken down by Data Classes.</li> </ul> </li> <li>Data Class labels per Study are reintroduces from Study Browser view.</li> <li>[Curators] Data upload via GUI: gct/generic data/vcf/facs data can be associated with any sample metadata attribute from template (except the key genestack:accession) when uploading data via Metadata Editor. This prevents users from need to edit original data to meet the rules of ODM data model.</li> <li>Templates: Ability to rename template when duplicating it.</li> </ul>"},{"location":"usage/release-notes/v1.50-v1.59/#fixed-major-issues","title":"Fixed Major Issues","text":"<ul> <li>GUI Issues:<ul> <li>Fixed error message when linking data to Sample metadata attribute with empty values in Study.</li> </ul> </li> </ul>"},{"location":"usage/release-notes/v1.50-v1.59/#other-changes","title":"Other Changes","text":"<ul> <li>Tasks Page: redesigned Task Manager is available from GUI.</li> <li>Python SDK, R SDK are not published in the release.</li> </ul>"},{"location":"usage/release-notes/v1.50-v1.59/#155-open-data-manager-2023-winter-release","title":"1.55 Open Data Manager 2023 Winter Release","text":""},{"location":"usage/release-notes/v1.50-v1.59/#new-features_1","title":"New Features","text":"<ul> <li>[Curators, Advanced, Admin] Manage Data<ul> <li>New Swagger Page: Introducing new endpoints for managing detached objects and deleting objects in ODM.<ul> <li><code>GET/detached-objects</code>: Identifies detached data objects (Samples, Libraries, Preparations, Tabular Data, VCF, and Flow Cytometry data) that are not linked to other objects, aiding in clean-up after incomplete data uploads or deletions.</li> <li><code>DELETE/data</code>: Facilitates cascade deletion of selected objects from ODM. For instance, deleting a Study also removes all linked objects (Samples, Libraries, Tabular Data, VCF, etc.). Access restricted to users with <code>MANAGE_ORGANIZATION</code> and <code>ACCESS_ALL_DATA</code> permissions.</li> </ul> </li> </ul> </li> <li>[Curators] Data Uploading Enhancements in GUI<ul> <li>Enhanced Tabular Data Handling: Supports specifying a separator character in file column headers for distinguishing between sample names and measurement types.</li> <li>Advanced Options:<ul> <li>Skip Zeroes (Sparse Data Matrix): Option to ignore cells with '0' values to optimize performance for datasets common in single-cell technologies.</li> </ul> </li> <li>Pre-validation: All data files uploaded from the local computer undergo a formatting compliance check before uploading.</li> <li>File Attachment Updates: If an attached file already exists in ODM, the system offers options to overwrite or rename the file.</li> </ul> </li> </ul>"},{"location":"usage/release-notes/v1.50-v1.59/#fixed-major-issues_1","title":"Fixed Major Issues","text":"<ul> <li> <p>GUI Issues:</p> <ul> <li>[Curators] Fixed the issue where Bulk Replace doesn't replace some empty values in the Metadata Editor.</li> <li>[Curators] Resolved incorrect behavior when copying/reassigning string values to integer/decimal types.</li> <li>[Curators] Addressed the issue preventing the import of Sample Metadata to a Study with existing attached files or failed tabular data uploads.</li> <li>[Users] Corrected the issue with incorrect data file names in export archives.</li> </ul> </li> <li> <p>Scripts and API Issues:</p> <ul> <li>[Curators, Advanced] Fixed the error occurring during the simultaneous upload of multiple files with over 2000 samples.</li> <li>[Curators, Advanced] Resolved the issue where the curation script does not publish changes.</li> <li>[Curators, Advanced] Aligned the behavior of the curation script with GUI functionality, particularly for the \"Re-assign\" feature.</li> <li>[Advanced] Addressed issues with streaming data endpoints, including excessive log entries, incomplete results under high demand, and malfunctioning with custom attribute-linked Tabular Data.</li> <li>[Advanced] Fixed errors related to long IP addresses and unexpected errors with Access Token requests.</li> </ul> </li> </ul>"},{"location":"usage/release-notes/v1.50-v1.59/#other-changes_1","title":"Other Changes","text":"<ul> <li>Data Archive Removal: All export data archives previously generated in the ODM GUI will be deleted. New export archives can be generated on demand.</li> <li>Custom SSE-KMS Key: Introduced the ability to specify a custom SSE-KMS key for data uploading in the ODM GUI.</li> </ul>"},{"location":"usage/release-notes/v1.50-v1.59/#154-open-data-manager-2023-summer-release","title":"1.54 Open Data Manager 2023 Summer Release","text":"<p>ODM \u2013 renamed to Open Data Manager.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#all-users-expanded-data-capabilities","title":"[All users] Expanded Data Capabilities","text":"<p>ODM now supports TSV-formatted data frames. This expansion beyond GCT 1.2, VCF, and FACS formats enables the upload of diverse data types such as proteomics, metabolomics, epigenomics, and analysis results. This requires adherence to the data frame specifications provided in the Usage section.</p> <p>Simply put, your data file can now accommodate multiple columns defining the measured feature and more than one measurement column per sample.</p> <p>Example of Mass Spectrometry data: Feature columns can encompass: <code>Gene Name</code>, <code>Protein Name</code>, <code>Peptide sequence</code>, <code>PTM site</code>, <code>M/Z ratio</code>, <code>Retention time</code>, etc. Measurements per sample may include: <code>Signal intensity</code>, <code>Signal quality</code>, etc.</p> <p>Data upload is possible via the GUI/API, and querying can be executed via the API (see details below).</p>"},{"location":"usage/release-notes/v1.50-v1.59/#curators-enhanced-data-uploading","title":"[Curators] Enhanced Data Uploading","text":"<p>The revised data uploading function is available as a BETA version in both the API and GUI. This feature will be improved in upcoming releases.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#advanced-api-improvements","title":"[Advanced] API Improvements","text":"<p>At present, uploading of TSV-formatted data is executed through Expression endpoints, with future releases introducing new endpoints for this operation.</p> <p>Utilize the following endpoints to upload TSV or bulk transcriptomics data in GCT 1.2:</p> <p><code>post/expression/gct</code></p> <p><code>post/import/expression</code></p> <p>We've added two new parameters for these endpoints (detailed descriptions available on corresponding Swagger pages):</p> <ul> <li><code>numberOfFeatureAttributes</code> - to specify the number of feature columns in the file.</li> <li><code>dataClass</code> - to denote the data type (e.g., proteomics, metabolomics, etc.).</li> </ul>"},{"location":"usage/release-notes/v1.50-v1.59/#curators-gui-adjustments","title":"[Curators] GUI Adjustments","text":"<p>The <code>Create new study</code> button has been relocated to the center of the screen.</p> <p></p> <p>The <code>Add Data (BETA)</code> button has been incorporated into the new Data tab (further details about the tab below).</p> <p></p> <p>You now have the ability to import TSV, GCT, VCF, or FACS data from your local computer or via a direct link.</p> <p></p> <p>Moreover, this button can also be used to attach any file to the study.</p> <p></p> <p>Please refer to the Usage section for more information on these functionalities.</p> <p>The Metadata Editor now includes an option to add new custom fields for Study and Data metadata.</p> <p></p>"},{"location":"usage/release-notes/v1.50-v1.59/#researchers-enhanced-data-browsing-and-export","title":"[Researchers] Enhanced Data Browsing and Export","text":"<p>The <code>Signal Type</code> filter has been replaced with the Data Class filter, which represents all available data types across studies.</p> <p></p> <p>The <code>Signal Type</code> column has been removed from the main study browser panel.</p> <p>The Expression/Variant/Flow Cytometry tabs have been removed from the Metadata Editor page.</p> <p>A new <code>Data</code> tab has been added to the Metadata Editor page. This tab displays a list of all data files uploaded for the study, organized by their respective <code>Data Class</code> parameter (selected during file upload) on the left panel.</p> <p></p> <p>Clicking on a file enables metadata editing [Curators only] and browsing.</p> <p>The metadata now includes four mandatory read-only fields that are auto-generated:</p> <ul> <li>Data Class - the data type selected during file upload.</li> <li>Features (string) - string feature column names present in the file (e.g., <code>Gene Name</code>).</li> <li>Features (numeric) - numeric feature column names present in the file (e.g., <code>M/Z ratio</code>).</li> <li>Value (numeric) - measurement types if more than one measurement is available per sample/library/preparation (e.g., <code>Fold Change</code>, <code>p-value</code>).     </li> </ul> <p>These fields are implemented to make the content of these files visible and searchable for data science users. We strongly advise against editing these fields in the template editor, as it could make these files inaccessible. If data is uploaded in the GCT format, <code>Features (string)</code>, <code>Features (numeric)</code>, and <code>Value (numeric)</code> fields are left empty (due to the standard structure of GCT files).</p>"},{"location":"usage/release-notes/v1.50-v1.59/#advanced-api-retrieval-improvements","title":"[Advanced] API Retrieval Improvements","text":"<p>The uploaded data can be searched and extracted using the API endpoint. Similar to the uploading process, data retrieval is performed through Expression parameters of Omics queries (Integration group), with future releases set to introduce new endpoints for this operation.</p> <p></p> <p>Each endpoint of Omics queries now has two updated parameters:</p> <ul> <li>In the <code>responseFormat</code> parameter, use the <code>multi_values</code> value to extract data in the new format. If your data has multiple features/measurements, they will be extracted in full. If the parameter is unspecified, the output returns only the first feature column and the first measurement per sample. This modification was introduced to maintain backward compatibility for applications built for GCT data extraction.</li> <li><code>exQuery</code> has been enhanced and now supports flexible searches across files of any content. Search parameters in <code>exQuery</code> include options for feature and measurement filtering:<ul> <li>To search by feature (feature keyword), specify the required column name, e.g., <code>feature.Genes=\"ZNF814\"</code>.</li> <li>To search by measurement type (value keyword), specify the required column name, e.g., <code>value.intensity &gt; A</code>.</li> </ul> </li> </ul> <p>New search capabilities include exact matches, multiple matches, range filtering, substring search, search by missing values, and more. Please refer to the corresponding endpoint descriptions in Swagger for details.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#known-issue","title":"Known Issue","text":"<p>If more than one file with the same name and extension is imported or attached via <code>Add Data (BETA)</code> button, then <code>Export</code> of the entire Study in one archive does not work.</p> <p>Do not import/attach files with exactly the same name (and extension) to avoid this issue. In case, two files with the same names were uploaded, you need to download them one by one.</p> <p></p>"},{"location":"usage/release-notes/v1.50-v1.59/#152","title":"1.52","text":""},{"location":"usage/release-notes/v1.50-v1.59/#gui-features","title":"GUI features","text":""},{"location":"usage/release-notes/v1.50-v1.59/#curators-revoking-access-to-a-study","title":"[Curators] Revoking access to a study","text":"<p>Added an ability to unshare a study (revoke access to a study) from a certain user group in Metadata Editor. The feature is available only to the study owner.</p> <p></p>"},{"location":"usage/release-notes/v1.50-v1.59/#curators-removing-a-multivalue-while-editing-samples-in-metadata-editor","title":"[Curators] Removing a multivalue while editing samples in Metadata Editor","text":"<p>Users can manually remove one of the values in a row with multiple values while editing a metadata sample in Metadata Editor. Previously, multi-valued \"No Value\" rows were automatically removed only after a new version of the sample metadata was published.</p> <p></p>"},{"location":"usage/release-notes/v1.50-v1.59/#fixed-issues","title":"Fixed issues","text":"<p>[Curators].[Metadata Editor] Sometimes sample attributes (with attached dictionaries) with empty values are marked in Metadata Editor as invalid.</p> <p>[Curators].[Metadata Editor] When multi-value rows in the composite sample attributes have no value, they are merged and not shown in Metadata Editor. In the example, there are \"Compound Treatment/Compound\", \"Compound Treatment/Dose\", and \"Compound Treatment/Unit\"; it is impossible to determine which \"Dose\" values correspond to a proper \"Compound\".</p> <p> </p> Before fixing the issue <p> </p> After fixing the issue <p>[Curators].[Metadata Editor] The default dictionary \"Cell type\" can not be used during the validation of the samples in Metadata Editor. Also, this dictionary cannot be reloaded into ODM.</p> <p>[Curators].[Metadata Editor] Incorrect sample count is shown on the bulk replace attribute editor dialogue.</p> <p>[Curators].[Template Editor] The exported json file with template attributes contains only the fields visible in the Template Editor. We have removed the outdated \"isSingle\" attribute from the file, which could lead to errors when reloading the template to ODM.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#api-changes","title":"API Changes","text":""},{"location":"usage/release-notes/v1.50-v1.59/#fixed-issues_1","title":"Fixed issues","text":"<p>[Advanced users] An issue with more than one AND operator in the omics metadata filters.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#151","title":"1.51","text":""},{"location":"usage/release-notes/v1.50-v1.59/#newupdated-features-in-this-release","title":"New/updated features in this release","text":"<p>API. Updating the feature of the data upload via NFS [Curators, Advanced].</p> Click here to expand <p>\u0421urators can import study files from a locally mounted Network File Storage (NFS) to ODM with \"write\" OR \"read-only\" access permission. There is no need to configure the \u201cwrite\u201d permission for the files, as it was before.</p> <p>Authentication in API via access token of an identity provider [Curators, Advanced].</p> Click here to expand <p>ODM API and the \"import_ODM_data.py\" script allow authentication with a Genestack API token OR with an access token of another identity provider. To specify a custom access token, use the \"Authorization\" header; to set the Genestack API token, use the \"Genestack-Api-Token\" header.</p> <p>Note: access token takes precedence, meaning that if both tokens are supplied, the access token will be used for processing the request. The expansion fully supports Azure Active Directory access tokens. For a different custom Identity Provider, please test ODM API beforehand.</p> <p>Linking samples and omics data by any custom key via API [Curators, Advanced].</p> Click here to expand <p>Previously: samples from metadata and omics data files could be linked only using the \"Sample Source Id\" attribute as a reference. Now curators can choose any sample metadata attribute (column) as a reference to link samples.</p> <p>Notes: only template attributes can be used for the linkage; if the value of the sample attribute for the linking changes, the relationship between samples and omics data is not updated automatically. More details about this feature you can find in the swagger, the endpoint <code>POST/integration/link/expression/group/{sourceId}/to/sample/group/{targetId}</code>, <code>linkingAttribute</code> parameter.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#fixed-issues-in-the-metadata-curation-process","title":"Fixed issues in the metadata curation process","text":"<p>[Curators] Fixed: a template attribute with invalid metadata is marked as \"non-template\" when a curator is editing sample metadata in Metadata Editor via the bulk replace.</p> <p>[Curators] Fixed: a formatting error appears for the study metadata view-only mode when the text in an attribute is not transferred to the next row.</p> <p>[Curators] Fixed: other minor bugs in Template Editor and Metadata Editor.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#fixed-issues-in-api","title":"Fixed issues in API","text":"<p>[Advanced] Fixed: the API endpoint GET/omics/expression/streamed-data does not return a proper error when a user specifies a wrong accession of the signal group in the groupAccession parameter. Now the endpoint returns an error 404 Not Found with the message <code>\"Group 'N' could not be found\"</code>.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#150","title":"1.50","text":""},{"location":"usage/release-notes/v1.50-v1.59/#newupdated-features-in-this-release_1","title":"New/updated features in this release","text":"<p>SCIM API for managing users and groups in ODM via Azure Active Directory [Admins].</p> Click here to expand <p>We have added SCIM API endpoints that allow the organization admin to manage users and user groups in ODM via Azure Active Directory. You can find all information about these endpoints and their limitations in Swagger in the \"Manage Organization\" section. Active Directory and ODM integration via SCIM endpoints instruction is located in the admin guides.</p> <p>Since the API endpoints have been developed according to the SCIM 2.0 specification, you can use them with any identity provider that supports working with SCIM. But since each identity provider has custom specifications, we recommend the solution pre-testing.</p> <p>We recommend calling user and group synchronization in Active Directory on behalf of the user with the \"Manage Groups\" permission so that the user can see and edit all groups on the instance, regardless of whether the user is a member of the groups or not.</p> <p>Quick start guide videos are added across ODM [Curators, Researchers].</p> Click here to expand <p>Each page contains a button that leads to a video explaining how to work with the page and the related main concepts. In addition, a welcome pop-up appears after the first login. The pop-up contains a link to the Quick Start Guide help page and all videos. Now users can get acquainted with the possibilities of ODM even faster and more conveniently on their own.</p>"},{"location":"usage/release-notes/v1.50-v1.59/#fixed-issues_2","title":"Fixed issues","text":"<p>[Curators] The import_ODM_data.py script incorrectly handled unexpected server responses from URL provided with <code>--server</code>: server is down for any reason or a user mistake. Now the script returns an error with clear instructions.</p>"},{"location":"usage/tools/odm-api/python/example/","title":"Usage of generated Python API Client","text":"<p>ODM APIs empower you to do large-scale, cross-study, and cross-omics analysis on-the-fly. The ODM OpenAPI Specification can be reviewed at <code>ODM_HOSTNAME/swagger/helper/</code>, where <code>ODM_HOSTNAME</code> is the URL of the ODM.</p>"},{"location":"usage/tools/odm-api/python/example/#requirements","title":"Requirements","text":"<ul> <li>Installed odm-api. See Installation odm-sdk</li> </ul>"},{"location":"usage/tools/odm-api/python/example/#example-of-usage","title":"Example of usage","text":"<p>Script to search through samples and display them in table format:</p> <pre><code>    import pandas as pd\n    import odm_api\n\n    configuration = odm_api.Configuration(\n        host=\"ODM_HOSTNAME\",\n        api_key={'Genestack-API-Token': 'ODM_TOKEN'}\n    )\n\n    api = odm_api.SampleSPoTAsCuratorApi(\n        api_client=odm_api.ApiClient(configuration=configuration)\n    )\n\n    query = '\"Disease\"=\"Healthy\" OR \"Disease\"=\"Alzheimer Disease\"'\n    samples = api.search_samples_as_curator(filter=query, page_offset=0)\n    print(pd.DataFrame.from_dict(samples.data[:5]))\n</code></pre> <p>The output:</p> <pre><code>  genestack:accession Sample Source ID Sample Name Organism     Sex  Disease   Age Age Unit Tissue Cell Type  ... Family.ID Donor Treatment/Treatment Name Specimen Type Tissue or Cell Type Sample Source Continental Group Code Sample Type Population Code Sample ID Continental Group\n0           GSF136813          HG00096        None     None    Male  Healthy  None     None   None      None  ...   HG00096                    Not treated           LCL               Blood         NHGRI                    EUR         DNA             GBR   HG00096       \"European \"\n1           GSF136814          HG00097        None     None  Female  Healthy  None     None   None      None  ...   HG00097                    Not treated           LCL               Blood         NHGRI                    EUR         DNA             GBR   HG00097       \"European \"\n2           GSF136815          HG00099        None     None  Female  Healthy  None     None   None      None  ...   HG00099                    Not treated           LCL               Blood         NHGRI                    EUR         DNA             GBR   HG00099       \"European \"\n3           GSF136816          HG00100        None     None  Female  Healthy  None     None   None      None  ...   HG00100                    Not treated           LCL               Blood         NHGRI                    EUR         DNA             GBR   HG00100       \"European \"\n4           GSF136817          HG00101        None     None    Male  Healthy  None     None   None      None  ...   HG00101                    Not treated           LCL               Blood         NHGRI                    EUR         DNA             GBR   HG00101       \"European \"\n</code></pre>"},{"location":"usage/tools/odm-api/python/installation/","title":"Installation of generated Python API Client","text":""},{"location":"usage/tools/odm-api/python/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3</li> <li>pip</li> </ul>"},{"location":"usage/tools/odm-api/python/installation/#instructions","title":"Instructions","text":""},{"location":"usage/tools/odm-api/python/installation/#install","title":"Install","text":"<ol> <li> <p>Start a console/terminal:</p> </li> <li> <p>Install the latest version using pip:</p> <pre><code>python3 -m pip install odm-api\n</code></pre> </li> </ol> <p>To install a specific version of a package, simply append the version number to the package reference in the command. For example: <code>odm-api==1.57.0</code></p>"},{"location":"usage/tools/odm-api/python/installation/#to-check-the-existing-version-and-view-all-available-console-commands-type","title":"To check the existing version, and view all available console commands, type","text":"<pre><code>python3 -m pip show --verbose odm-api\n</code></pre>"},{"location":"usage/tools/odm-api/python/installation/#you-can-always-remove-the-package-with-a-help-of-this-command","title":"You can always remove the package with a help of this command","text":"<pre><code>python3 -m pip uninstall odm-api\n</code></pre>"},{"location":"usage/tools/odm-api/r/example/","title":"Usage of generated R API Client","text":""},{"location":"usage/tools/odm-api/r/example/#requirements","title":"Requirements","text":"<ul> <li>Installed odm-api. See Installation odm-sdk</li> </ul>"},{"location":"usage/tools/odm-api/r/example/#example-of-usage","title":"Example of usage","text":"<p>Script to search through samples and display them in table format:</p> <pre><code>library(odmApi)\napi_instance &lt;- SampleSPoTAsCuratorApi$new()\napi_instance$api_client$api_keys[\"Genestack-API-Token\"] &lt;- 'ODM_TOKEN'\napi_instance$api_client$base_path &lt;- 'https://ODM_HOSTNAME'\nquery &lt;- '\"Disease\"=\"Healthy\" OR \"Disease\"=\"Alzheimer Disease\"'\nresult &lt;- api_instance$SearchSamplesAsCurator(filter=query, response_format=\"term_id\", returned_metadata_fields=\"minimal_data\")\nresult$content$data[1:5]\n</code></pre> <p>The output (shorten):</p> <pre><code>  genestack:accession Sample Source ID Sample Name Organism     Sex\n1           GSF136813          HG00096        None     None    Male\n2           GSF136814          HG00097        None     None  Female\n3           GSF136815          HG00099        None     None  Female\n4           GSF136816          HG00100        None     None  Female\n5           GSF136817          HG00101        None     None    Male\n</code></pre>"},{"location":"usage/tools/odm-api/r/installation/","title":"Installation of generated R API Client","text":""},{"location":"usage/tools/odm-api/r/installation/#requirements","title":"Requirements","text":"<ul> <li>R</li> </ul>"},{"location":"usage/tools/odm-api/r/installation/#instructions","title":"Instructions","text":""},{"location":"usage/tools/odm-api/r/installation/#install","title":"Install","text":"<ol> <li> <p>Install dependencies in advance</p> <pre><code>install.packages(\"jsonlite\")\ninstall.packages(\"httr\")\ninstall.packages(\"base64enc\")\ninstall.packages(\"stringi\", dependencies=TRUE, INSTALL_opts = c('--no-lock'))\ninstall.packages(\"stringr\", dependencies=TRUE, INSTALL_opts = c('--no-lock'))\n</code></pre> </li> <li> <p>Install the latest version:</p> <pre><code>genestackRepo &lt;- \"https://public-nexus.devops.gs.team/repository/r-releases\"\ninstall.packages(\"odmApi\", repos = genestackRepo)\n</code></pre> </li> <li> <p>(Optional) Install specific version:</p> <pre><code>genestackRepo &lt;- \"https://public-nexus.devops.gs.team/repository/r-releases\"\ninstall_specific_version_from_nexus &lt;- function(pkg, version = NULL) {\n  pkg_name &lt;- paste0(pkg, \"_\", version, \".tar.gz\")\n  url &lt;- paste(genestackRepo, \"src/contrib\", pkg_name, sep = \"/\")\n  install.packages(url, repos = NULL, method=\"libcurl\")\n}\nodmApiVersion &lt;- \"1.57.0\"\ninstall_specific_version_from_nexus(\"odmApi\", version = odmApiVersion)\n</code></pre> </li> </ol>"},{"location":"usage/tools/odm-sdk/configuration/","title":"Initial configuration of odm-sdk","text":""},{"location":"usage/tools/odm-sdk/configuration/#requirements","title":"Requirements","text":"<ul> <li>Installed odm-sdk. See Installation odm-sdk</li> </ul>"},{"location":"usage/tools/odm-sdk/configuration/#instructions","title":"Instructions","text":""},{"location":"usage/tools/odm-sdk/configuration/#configure","title":"Configure","text":"<ol> <li> <p>Retrieve an Access (Bearer) Token, or obtain an API token by logging into ODM and clicking the profile link under     the username.</p> <p>See an example for Public user below:</p> <p></p> <p>You need to click on the \"Create new token\" button, so you will receive an email with a link to your token. Please open the link in the email and save the token for future needs.</p> </li> <li> <p>Set up your account with the Genestack Python client from a console</p> <pre><code>odm-user-setup -H https://domain_name/\n</code></pre> </li> <li> <p>Type \u2018add\u2019 to enter a new user, enter an alias for the user.</p> </li> <li>Enter the host name, which should be of the format: https://domain_name/.</li> <li> <p>Then select suitable authentication method (1 or 2) and input the content of the token you received in step 1:</p> <pre><code>1) by token\n2) by access token\n3) by email and password\nSelect authentication: 1\nHost: https://domain_name/\nPlease specify Genestack API token for \"my_user\":\n</code></pre> </li> <li> <p>Type \u2018quit' to exit the user-setup.</p> </li> </ol>"},{"location":"usage/tools/odm-sdk/installation/","title":"Installation odm-sdk","text":""},{"location":"usage/tools/odm-sdk/installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3</li> <li>pip</li> </ul>"},{"location":"usage/tools/odm-sdk/installation/#instructions","title":"Instructions","text":""},{"location":"usage/tools/odm-sdk/installation/#install","title":"Install","text":"<ol> <li> <p>Start a console/terminal:</p> </li> <li> <p>Install the latest version using pip:</p> <pre><code>python3 -m pip install odm-sdk\n</code></pre> </li> </ol> <p>To install a specific version of a package, simply append the version number to the package reference in the command. For example: <code>odm-sdk==1.57.0</code></p>"},{"location":"usage/tools/odm-sdk/installation/#to-check-the-existing-version-and-view-all-available-console-commands-type","title":"To check the existing version, and view all available console commands, type","text":"<pre><code>python3 -m pip show --verbose odm-sdk\n</code></pre>"},{"location":"usage/tools/odm-sdk/installation/#you-can-always-remove-the-package-with-a-help-of-this-command","title":"You can always remove the package with a help of this command","text":"<pre><code>python3 -m pip uninstall odm-sdk\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/creating-new-dictionary/","title":"How to create new simple dictionary","text":"<p>Dictionaries can be loaded to ODM in CSV, JSON, OWL, OBO or TTL formats. In order to create a simple CSV format dictionary create a file in CSV format, add \u201cLabel\u201d to the first line and then add each value one per line. Note labels with commas must be embedded within three double quotes.</p> <p>For example:</p> <pre><code>Label\ng\nkg\n\"\"\"value, continued\"\"\"\n</code></pre> <p>Example of .csv file:</p> <p>body_weight_unit.csv</p> <p>Note</p> <p>Please note that values in dictionary always have String format in ODM, even if they are numbers.</p>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/default-dictionaries/","title":"Default dictionaries","text":"<p>Below you can see a table with description of ODM dictionaries:</p> Dictionary Description Is used by Default template NCBI Taxonomy A standard hierarchical nomenclature and classification dictionary for organisms. The original file is available at http://www.berkeleybop.org/ontologies/ncbitaxon.owl https://s3.amazonaws.com/bio-test-data/Ontologies/ncbitaxon.owl Yes ChEBI Ontology The ChEBI ontology focuses on chemical nomenclature and structures, and provides a wide range of other chemical information such as formulae and links to other databases. The original file can be accessed via the web at ftp://ftp.ebi.ac.uk/pub/databases/chebi/ontology/chebi.owl Yes Cellosaurus Controlled Vocabulary A controlled vocabulary which describes all cell lines used in biomedical research. The original file is available at https://raw.githubusercontent.com/calipho-sib/cellosaurus/4895a46f1475ed7ad62f772924d0c1ecb4b5ce6f/cellosaurus.obo Yes Uberon Anatomical Entities An integrated cross-species ontology covering anatomical structures in animals. The original file is available at http://purl.obolibrary.org/obo/uberon/releases/2023-10-27/uberon-simple.owl Yes Cell Type The Cell Ontology is a structured controlled vocabulary for cell types in animals. The original data is available via the link http://purl.obolibrary.org/obo/cl.owl Yes Disease Ontology Extended An ontology for describing the classification of human diseases organized by etiology. The original file is available at http://purl.obolibrary.org/obo/doid.owl Yes Disease Ontology An ontology for describing the classification of human diseases organized by etiology. The original file is available at http://purl.obolibrary.org/obo/doid.owl Therapeutic Area A non-hierarchical controlled vocabulary for Therapeutic Area field Yes Sequencing Platforms A non-hierarchical controlled vocabulary contains list of sequencing platforms Yes Sex A non-hierarchical controlled vocabulary for Sex metainfo field Yes Experiment Instrument This dictionary covers different experiment instruments Yes Data Species This dictionary covers different data species Yes Library Type This dictionary covers different library types Yes Experiment Type This dictionary covers different experiment types Yes Scope This dictionary covers different preparation scopes Yes miRBase microRNA database entities Micro RNA controlled vocabulary (release 22.1).  The original data (mirBase.dat and mirna_species.txt) are available at miRBase Uniprot Homo Sapiens Uniprot proteins dictionary for Homo Sapiens.  The original data are available using query UniProt Gene Ontology A controlled vocabulary describing the gene functions according to three aspects: biological process, molecular function and cellular component. The original file is available at http://purl.obolibrary.org/obo/go.owl Cell Ontology A structured controlled vocabulary for cell types. The original file is available at http://purl.obolibrary.org/obo/cl/releases/2020-03-02/cl-basic.owl Units - Dimensionless Microarray Platforms A non-hierarchical controlled vocabulary contains list of microarray platforms Methods A non-hierarchical controlled vocabulary which covers methods and approaches used in bioinformatics Ethnic Groups A non-hierarchical controlled vocabulary including list of ethnic groups <p>There are several dictionaries generated inside ODM:</p> <ul> <li>Bio counts</li> <li>Dose</li> <li>Energy</li> <li>Length</li> <li>Time</li> </ul> <p>The most recent dictionary versions, used in ODM, are located under s3 bucket and available via http link. Example: https://odm-init.s3.amazonaws.com/dictionaries/cellosaurus.obo</p>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/exporting-ontologies-from-odm/","title":"How to get ontologies from ODM","text":"<ol> <li>From the Dashboard go to Template Editor    </li> <li>You will see all the templates    </li> <li>To review ontologies used in a particular template, open the template by clicking on the title.    </li> <li>You will see all the attributes, including which are associated with Dictionaries and you can square the list of Dictionaries used.</li> <li>To get source-file of ontology, you will need accession (e.g. <code>GSF000026</code>)</li> <li>Then you will need to go to the File Manager by a direct link: <code>[your_host]/ui/files</code></li> <li>Put ontology Accession in the search field and click on the search button. You will see templates which use this dictionary and the dictionary itself.      There are templates files in the search results as well as dictionary files, to easily find a dictionary, look at the column \"Type\" and find \"Dictionary\":    </li> <li>Click on the more menu, you will see the context menu, click on \"More info\"    </li> <li>To download the source file click on the link from the Data URL attribute:        Or you can go to the source in the description:    </li> </ol>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/loading-new-ontology/","title":"How to load custom dictionaries (ontologies)","text":"<p>This article explains how to load custom dictionaries (ontologies) in ODM.</p> <p>Uploading a dictionary with the same name as a previous dictionary will create a new version (new accession) of the dictionary and the system will mark the old version as obsolete, which will highlight it red in the template editor. Templates will need to be updated to use the new dictionary.</p>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/loading-new-ontology/#requirements","title":"Requirements","text":"<ul> <li>Configured odm-sdk. See Configured odm-sdk</li> <li>User should have Bearer Token or API token. See Getting a Genestack API token</li> <li>A file describing dictionaries, e.g.: dictionaries.json</li> <li>One or more dictionaries in CSV, JSON, OWL, OBO or TTL formats, hosted at FTP or HTTP web addresses, see dictionary example</li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/loading-new-ontology/#setting-up-dictionary-namelocation","title":"Setting up dictionary name/location","text":"<p>Open the <code>dictionaries.json</code> file and replace the <code>name</code>, <code>url</code> and <code>description</code> sections with the desired dictionary name as it will appear in ODM, dictionary location, and dictionary description.</p> <pre><code>[\n    {\n        \"name\": \"NCI Thesaurus\",\n        \"url\": \"http://purl.obolibrary.org/obo/ncit.owl\",\n        \"description\": \"NCI Thesaurus (NCIt) is a reference terminology that includes broad coverage of the cancer domain, including cancer related diseases, findings and abnormalities. The NCIt OBO Edition aims to increase integration of the NCIt with OBO Library ontologies\"\n    }\n]\n</code></pre> <p>Multiple dictionaries can be supplied by repeating the section in curly brackets.</p>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/loading-new-ontology/#running-the-command-to-import-dictionaries","title":"Running the command to import dictionaries","text":"<p>To explore the full list of supported arguments use the following command:</p> <pre><code>odm-update-dictionary -h\n</code></pre> <p>Run the following command from your terminal:</p> <pre><code>odm-update-dictionary -u YOUR_ALIAS_FOR_USER --file_with_dictionaries /FULL_PATH_TO_THE_DICTIONARIES_JSON_FILE/dictionaries.json\n</code></pre> <p><code>-u</code> [optional] parameter should contain the alias for the user you set up with the Genestack python client previously. <code>-H [hostname]</code> [optional] hostname for the environment being used; you can use either <code>-u</code> or <code>-H</code>. <code>--file_with_dictionaries</code> parameter should contain full path to the <code>dictionaries.json</code> file - replace <code>FULL_PATH_TO_THE_DICTIONARIES_JSON_FILE</code> with this path. or run</p> <pre><code>odm-update-dictionary -u YOUR_ALIAS_FOR_USER --file_with_dictionaries dictionaries.json\n</code></pre> <p>if <code>dictionaries.json</code> is presented in the current working directory.</p> <p>Once loaded the dictionary needs to be indexed. This will occur automatically in the background but can take several minutes (~25 minutes for a 600MB ontology). The indexing task can be monitored in the tasks log.</p>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/loading-new-ontology/csv-dictionary-format/","title":"CSV dictionary format","text":"<p>Custom dictionaries can be uploaded to ODM in the form of list files. List files consist of a header line containing label or name,label. Followed by lines of dictionary terms, one per term, in the format <code>&lt;label&gt;</code> or <code>&lt;name&gt;,&lt;label&gt;</code>. If labels contain commas the whole label term need to be enclosed in three double quotes, \u201c\u201c\u201cexample of label, with comma\u201d\u201d\u201d.</p> <p>Example label only dictionary: TherapeuticArea_Vocabulary1.csv</p> <pre><code>label\n\"\"\"Cardiovascular, Renal and Metabolism [CVRM]\"\"\"\nGastrointestinal [GI]\nInfection [INFEC]\nAutoimmune [AI]\nNeuroscience [NEURO]\nOncology [ONC]\nImmuno-oncology [IMMUONC]\nInflammation [INFLA]\nRespiratory [RESP]\nVaccines [VA]\n</code></pre> <p>Example name,label dictionary: TherapeuticArea_Vocabulary2.csv</p> <pre><code>name,label\n[CVRM],\"\"\"Cardiovascular, Renal and Metabolism\"\"\"\n[GI],Gastrointestinal\n[INFEC],Infection\n[AI],Autoimmune\n[NEURO],Neuroscience\n[ONC],Oncology\n[IMMUONC],Immuno-oncology\n[INFLA],Inflammation\n[RESP],Respiratory\n[VA],Vaccines\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/loading-new-ontology/skos-dictionary/","title":"Dictionaries in SKOS namespace","text":"<p>ODM also supports dictionaries in SKOS namespace. This feature is useful to organize terms in a hierarchical structure, which enables more advanced search capabilities. Both RDF/XML and TURTLE formats of dictionaries are supported. Predicates <code>skos:broader</code>, <code>skos:narrower</code> <code>skos:related</code>, <code>skos:definition</code>, and <code>skos:exactMatch</code> are recognized and utilized by ODM.</p>"},{"location":"usage/tools/odm-sdk/terminal/dictionaries-and-ontologies/loading-new-ontology/skos-dictionary/#example-of-skos-dictionary","title":"Example of SKOS dictionary","text":"<p>Here are the examples of an artificial short SKOS dictionary in TURTLE and in RDF/XML formats:</p> TURTLE format <pre><code>@prefix skos: &lt;http://www.w3.org/2004/02/skos/core#&gt; .\n\n&lt;http://vocabulary.boehringer-ingelheim.com/BodySystem/562&gt;\n a skos:Concept ;\n skos:prefLabel \"Cerebral cortex\"@en .\n\n&lt;http://vocabulary.boehringer-ingelheim.com/BodySystem/104&gt;\n a skos:Concept ;\n skos:narrower &lt;http://vocabulary.boehringer-ingelheim.com/BodySystem/562&gt; ;\n skos:prefLabel \"Brain\"@en .\n\n&lt;http://vocabulary.boehringer-ingelheim.com/BodySystem/562&gt; skos:broader &lt;http://vocabulary.boehringer-ingelheim.com/BodySystem/104&gt; .\n</code></pre> RDF/XML format <pre><code>&lt;?xml version=\"1.0\" encoding=\"utf-8\" ?&gt;\n&lt;rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n         xmlns:skos=\"http://www.w3.org/2004/02/skos/core#\"&gt;\n\n    &lt;skos:Concept rdf:about=\"http://vocabulary.boehringer-ingelheim.com/BodySystem/562\"&gt;\n        &lt;skos:prefLabel xml:lang=\"en\"&gt;Cerebral cortex&lt;/skos:prefLabel&gt;\n        &lt;skos:broader&gt;\n            &lt;skos:Concept rdf:about=\"http://vocabulary.boehringer-ingelheim.com/BodySystem/104\"&gt;\n                &lt;skos:narrower rdf:resource=\"http://vocabulary.boehringer-ingelheim.com/BodySystem/562\"/&gt;\n                &lt;skos:prefLabel xml:lang=\"en\"&gt;Brain&lt;/skos:prefLabel&gt;\n            &lt;/skos:Concept&gt;\n        &lt;/skos:broader&gt;\n\n    &lt;/skos:Concept&gt;\n\n&lt;/rdf:RDF&gt;\n</code></pre> <p>This dictionary defines two concepts: <code>Brain</code> and <code>Cerebral cortex</code>. Uploading this dictionary to ODM not only will allow you to assign a template attribute to have values <code>Brain</code> and <code>Cerebral cortex</code> but also will rate the full-text search results according to these relationships: if a user searches for <code>Brain</code>, the search results will also include studies that have <code>Cerebral cortex</code> as a value, and vice versa: a search for <code>Cerebral cortex</code> will also include studies that have <code>Brain</code> value, but with a lower score.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/","title":"Curation script","text":""},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#introduction","title":"Introduction","text":"<p>This script allows the curation of metadata by transforming incorrect metadata values to correct ones based on controlled vocabularies (for example, \u201cNCBI Taxonomy\u201d) and manually prepared files with rules for matching. Synonyms, if provided, can assist in the matching process.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#requirements","title":"Requirements","text":"<ul> <li>Configured odm-sdk. See Configured odm-sdk</li> <li>The user should be a member of Curator group and have Bearer Token or API token. See Getting a Genestack API token</li> <li> <p>File with curation rules. How to correctly write such file is described below.</p> <p>Example: rules.json written for sample metadata samples.tsv.</p> </li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#curation-script-usage","title":"Curation script usage","text":"<p>To explore the full list of supported arguments use the following command:</p> <pre><code>odm-curate-study -h\n</code></pre> <p>Curation can be carried out by running the Python metadata curation script <code>odm-curate-study</code>. This can be used to perform automated curation of metadata associated with experiments and assays on Genestack. The script takes as input the accessions of Genestack study or studies which should contain the samples to be curated. You must also supply a rules file, which specifies the rules for mapping.</p> <pre><code>odm-curate-study --rules &lt;rules.json&gt; &lt;study accession(s)&gt; -H GENESTACK_ENDPOINT_ADDR\n</code></pre> <p>Where <code>GENESTACK_ENDPOINT_ADDR</code> is the URL of the Genestack platform.</p> <p>Space is used as a separator in case of multiple studies. Example:</p> <pre><code>odm-curate-study --rules rules.json GSF000100 GSF000200 -H GENESTACK_ENDPOINT_ADDR\n</code></pre> <p>You can test a curation rule before applying it with the --dry-run parameter. This will connect to the server and report matches in the task output log (see later) but not actually change any data.</p> <pre><code>odm-curate-study --rules &lt;rules.json&gt; --dry-run &lt;study accession&gt; -H GENESTACK_ENDPOINT_ADDR\n</code></pre> <p>By default, if the target key already contains information it will not be overwritten and a warning will be noted in the logs, however you can force this using the --overwrite flag. This does not affect attributes set as 'read-only' in the template.</p> <pre><code>odm-curate-study --rules &lt;rules.json&gt; --overwrite &lt;study accession&gt; -H GENESTACK_ENDPOINT_ADDR\n</code></pre> <p>Example usage for acting on study GSF123456:</p> <pre><code>odm-curate-study --rules rules.json --overwrite GSF123456 -H GENESTACK_ENDPOINT_ADDR\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#metadata-mapping-rules","title":"Metadata mapping rules","text":"<p>The curation application uses a <code>rules.json</code> file which defines the mapping rules using the <code>--rules &lt;rule_file&gt;</code> argument. The rules must be provided as a JSON file which contains an array of objects, where each object describes a metadata mapper. The mapping script will search for raw uncurated metadata values in a list of input keys (also called \"raw keys\"), try to map them to a \"curated\" value (using a synonym-aware dictionary or custom rules) and store the curated value in a target key. Values are case-sensitive. The valid attributes for the metainfo mapper are as follows:</p> <ul> <li>dictionary (string, optional) - the name of a public Genestack dictionary used as a source of valid terms - if     specified mappings are not found in a supplied dictionary then a warning is given in the logs;</li> <li>genestack_key (string, mandatory) - target metainfo key (e.g. \u2018Sex\u2019);</li> <li>object_type (string, mandatory) - the specific data object being targeted (e.g. 'study' or 'sample', must be     lowercase.)</li> <li>raw_keys (list of strings, mandatory) - comma separated list of names of the raw (ie from import) metadata     keys in which raw values will be looked up (e.g. \u2018sourceData:ae.sample.Characteristics [Sex]\u2019);</li> <li>rules (object of strings, optional) - rules to map raw values to terms from dictionaries/ontologies.     For example, below is a JSON rules file to define custom mapping rules for the \"Sex\" metainfo attribute. This will     copy data from a column (<code>sourceData:ae.sample.Characteristics [Sex]</code>) to the correct one (<code>Sex</code>)</li> </ul> <pre><code>[\n    {\n        \"genestack_key\": \"Sex\",\n        \"object_type\": \"sample\",\n        \"raw_keys\": [\"sourceData:ae.sample.Characteristics [Sex]\"]\n    }\n]\n</code></pre> <p>To do the same, but also map data values to specific terms (\"m\" to \"male\", \"f\" to \"female\", \"?\" to \"unknown\"), use the following:</p> <pre><code>[\n    {\n        \"genestack_key\": \"Sex\",\n        \"object_type\": \"sample\",\n        \"raw_keys\": [\"sourceData:ae.sample.Characteristics [Sex]\"],\n        \"rules\": {\n            \"m\": \"male\",\n            \"f\": \"female\",\n            \"?\": \"unknown\"\n        }\n    }\n]\n</code></pre> <p>The end result is as per the below tables.</p> <p>Before:</p> Sex m f ? <p>After:</p> Sex male female unknown <p>Finally, a dictionary can be supplied in the rules. If the value (first mapped by rules) matches to one of the term's synonyms it will be replaced with the preferred term.</p> <pre><code>[\n    {\n        \"genestack_key\": \"Sex\",\n        \"object_type\": \"sample\",\n        \"raw_keys\": [\"sourceData:ae.sample.Characteristics [Sex]\"],\n        \"dictionary\": \"Sex\"\n    }\n]\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#key_with_unit-mapper","title":"Key_with_unit Mapper","text":"<p>If samples have a key with unit values stored in 1 attribute, e.g. <code>\u201cTime\u201d=\u201d7 days\u201d</code>, it is possible to curate the values so that they are displayed in 2 separate attributes in ODM: <code>\u201cTime/value\u201d=\u201d7\u201d, \u201cTime/unit\u201d=\u201ddays\u201d</code>.</p> <p>To split the value and its associated unit, the script will attempt to use the whitespace character(s) as a delimiter. If there is a space, the script puts the part before the first space in the <code>Value</code> attribute, everything after the first space in the <code>Unit</code> attribute (even if there are more than 1 space). Genestack keys should be specified for both, using a comma separated list. If there are no spaces, everything is put in the <code>Value</code> attribute, the <code>Unit</code> attribute is left empty. We rely on manual curation in this case. Example of using the mapper with units:</p> <pre><code>[\n    {\n        \"object_type\": \"sample\",\n        \"genestack_key\": [\"Treatment/dose/value\", \"Treatment/dose/unit\"],\n        \"raw_keys\": [\"Value[Dose]\"],\n        \"dictionary\": \"Units - Dose/Mass/Volume\"\n    }\n]\n</code></pre> <ul> <li> <p>Sample A:</p> <ul> <li>Before: <code>\"Parameter Value[Dose]\"=7 ug/ml</code></li> <li>After: <code>\"Treatment/dose/value\"=7, \"Treatment/dose/unit\"=microgram per millilitre</code></li> </ul> </li> <li> <p>Sample B:</p> <ul> <li>Before: <code>\"Parameter Value[Dose]\"=7 ug per ml</code></li> <li>After: <code>\"Treatment/dose/value\"=7, \"Treatment/dose/unit\"=ug per ml</code></li> </ul> </li> <li> <p>Sample C:</p> <ul> <li>Before: <code>\"Parameter Value[Dose]\"=7ug/ml</code></li> <li>After: <code>\"Treatment/dose/value\"=7ug/ml, \"Treatment/dose/unit\"=null</code></li> </ul> </li> </ul> <p>Before:</p> Sample Name Dose Sample A 7 ug/ml Sample B 7 ug per ml Sample C 7ug/ml <p>After:</p> Sample Name Dose Dose Unit Sample A 7 ug/ml Sample B 7 ug per ml Sample C 7ug/ml <p>Supported case: We support curation of multiple values with units for a single sample with the <code>\u201ckey_with_unit\u201c</code> mapper, e.g.: Sample X {Attribute_1=A|B; Attribute_2=X|Y} A= Paracetamol; X=5 mg B= Analgin; Y=0.5 g</p> <p>Before:</p> Sample Name Medicine Dose Sample Paracetamol  5mg  Analgin  0.5 g <p>After:</p> Sample Name Medicine Dose Dose Unit Sample Paracetamol  5   mg  Analgin  0.5  g  <p>Unsupported case: Changing a single value to multiple values for this mapper is not supported. Sample X {Attribute_1=A; Attribute_2=X|Y} A= Paracetamol; X=2.5 g | Y=2.5 g Before:</p> Sample Name Medicine Dose Sample Paracetamol  5mg  <p>After:</p> Sample Name Medicine Dose Dose Unit Sample Paracetamol  2.5   g   2.5   g"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#reassigning-attributes","title":"Reassigning attributes","text":"<p>When it comes to matching attribute names, the script works similarly to the \u201cReassign\u201d feature of the Metadata Editor application. That means that if a raw_key from the rules file is detected among the attributes, the values are reassigned to the corresponding genestack_key, and the original attribute raw_key is deleted.</p> <p>Rule:</p> <pre><code>[\n    {\n        \"genestack_key\": \"Disease\",\n        \"object_type\": \"sample\",\n        \"raw_keys\": [\"Illness\", \"DISEASE\"]\n    }\n]\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#case-1","title":"Case 1","text":"<p><code>raw_key</code> is a non-template attribute, <code>genestack_key</code> is a template attribute. After curation values are reassigned to <code>genestack_key</code>, and the original attribute <code>raw_key</code> is deleted.</p> <p>Before:</p> Disease Illness Sample 1  A  Sample 2  B  <p>After:</p> Disease Sample 1 A  Sample 2 B <p>The above is valid in most cases, but the behaviour can differ for some specific cases which are described below.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#case-2","title":"Case 2","text":"<p>If multiple raw keys are defined for the same attribute, the values are taken from the first non empty raw key found for the sample, the rest raw keys are ignored.</p> <p>Multiple <code>raw_key</code>s from the rules are found. All <code>raw_key</code>s are non-template attributes. The first <code>raw_key</code> attribute (<code>Illness</code>) has a value for the <code>Sample 1</code>, but does not have any value for the <code>Sample 2</code>. Hence the value from the second <code>raw_key</code> attribute (<code>DISEASE</code>) is taken for the <code>Sample 2</code>. The <code>raw_key</code> attribute which values were re-assigned for all samples (<code>Illness</code>) is deleted. The partially re-assigned attribute (<code>DISEASE</code>) still presents in the table, but only with values which were not reassigned.</p> <p>Before:</p> Disease Illness DISEASE Sample 1 A A1 Sample 2 B1 <p>After:</p> Disease DISEASE Sample 1 A A1 Sample 2 B1 <p>Note: The described case is quite rare since usually attributes with the same meaning will have the same name across all samples in one study. Multiple raw keys are provided mostly for running the script on multiple studies from different sources where attributes with the same meaning can have different names.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#case-3","title":"Case 3","text":"<p><code>raw_key</code> is a template attribute. This case is considerably rare too, since the main purpose of the Curation script is to match non-template attributes of non-harmonised metadata to the template attributes. \u201cRe-assign\u201d feature cannot be used for template attributes, since they cannot be deleted. Hence, the values will be copied from raw_key to <code>genestack_key</code> and preserve <code>raw_key</code> in the same state as before the curation.</p> <p>Before:</p> Disease Illness Sample 1 A Sample 2 B <p>After:</p> Disease Illness Sample 1 A A Sample 2 B B"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#read-only-attributes","title":"Read only attributes","text":"<p>Attributes set as read only in the template associated with the study cannot be curated, and a warning is displayed in the logs. The <code>overwrite</code> flag does not affect this behaviour.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#multiple-rules-for-a-single-attribute","title":"Multiple rules for a single attribute","text":"<p>If multiple rules for the same attribute are found the warning message is displayed in the logs:</p> <pre><code>Multiple curation rules were detected for the attribute X.\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/study/curation-script/#progress-logs","title":"Progress, Logs","text":"<p>You can track the progress of the curation process in the Genestack Task Manager: </p> <p>The results of mapping are shown in the output logs: </p>"},{"location":"usage/tools/odm-sdk/terminal/study/deleting-study/","title":"How to delete a study","text":""},{"location":"usage/tools/odm-sdk/terminal/study/deleting-study/#requirements","title":"Requirements","text":"<ul> <li>Configured odm-sdk. See Configured odm-sdk</li> <li>The user should have the \"Manage organisation\" permission and have Bearer Token or API token. See Getting a Genestack API token</li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/deleting-study/#instructions","title":"Instructions","text":"<p>To explore the full list of supported arguments use the following command:</p> <pre><code>odm-delete-study -h\n</code></pre> <p>Warning</p> <ol> <li>Only users with the \u201cManage organisation\u201d permission can delete studies.</li> <li>The script doesn\u2019t check that the file with the provided accession actually exists so if nothing is deleted but the script runs correctly it will still output 'Success'.</li> <li>The script doesn\u2019t check the type of the file so if a template\u2019s accession is provided instead of a study\u2019s accession the template will be deleted. However, for deletion of templates please use the script from How to delete a template</li> </ol> <p>Run the script and follow its login instructions, replacing the host name with the name of the instance the script will apply to. The script will print \u201cSuccess\u201d or an error stacktrace if there\u2019s an error.</p> <pre><code>odm-delete-study --accession GSF244344 -H HOSTNAME\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/study/loading-from-geo/","title":"Loading from GEO","text":"<p>This article describes how to prepare a series matrix file from GEO to be loaded to ODM.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/loading-from-geo/#requirements","title":"Requirements","text":"<ul> <li>Configured odm-sdk. See Configured odm-sdk</li> <li>Having <code>pandas</code> library installed. We recommend using the latest version available.</li> <li>Data file from GEO, for example GSE29746_series_matrix.txt</li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/loading-from-geo/#instructions","title":"Instructions","text":"<p>Run the script providing the <code>GSE29746_series_matrix.txt</code> file as an argument</p> <pre><code>odm-geo-prepare GSE29746_series_matrix.txt\n</code></pre> <p>As a result, the script creates the folder with 3 files (example), that you can use to load to ODM. For example:</p> <pre><code>\u251c\u2500\u2500 GSE29746\n\u2502   \u251c\u2500\u2500 GSE29746_expression.gct\n\u2502   \u251c\u2500\u2500 GSE29746_samples.tsv\n\u2502   \u2514\u2500\u2500 GSE29746_study.tsv\n</code></pre> <p>Load your files to AWS S3 and then to ODM following the instructions</p>"},{"location":"usage/tools/odm-sdk/terminal/study/sharing-study/","title":"How to share a study programmatically","text":""},{"location":"usage/tools/odm-sdk/terminal/study/sharing-study/#requirements","title":"Requirements","text":"<ul> <li>Configured odm-sdk. See Configured odm-sdk</li> <li>The user should be a member of Curator group and have Bearer Token or API token. See Getting a Genestack API token</li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/sharing-study/#instructions","title":"Instructions","text":"<p>To explore the full list of supported arguments use the following command:</p> <pre><code>odm-share-study -h\n</code></pre> <p>Please note that there are several limitations:</p> <ol> <li>The script should be launched under the study owner user.</li> <li>The script will fail if the user attempts to share studies with a group name that is used more than once in groups they are a member of (ie, group names should not be duplicated).</li> </ol> <ol> <li>Prepare the data for script: you need accessions of the studies you want to share and the names of the user groups with which you want to share they studies.</li> <li>Run the script and follow its login instructions, replacing the host name with the name of the instance the script will apply to. The script will print \u201cSuccess\u201d or an error stacktrace if there is an error.</li> </ol> <pre><code>odm-share-study --study_accession GSF013340 --group_name GroupName -H HOST\n</code></pre> <p>If a group name contains spaces use quotes around group name:</p> <pre><code>odm-share-study --study_accession GSF000745 --group_name 'Group name with space' -H HOST\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/","title":"How to load and share a study, samples and associated data via async loading","text":"<p>This article explains how to load studies via script and share them with the organisation (via GUI). More information about supported files can be found also in the user guide.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#requirements","title":"Requirements","text":"<ul> <li>Configured odm-sdk. See Configured odm-sdk</li> <li>Having <code>pandas</code> library installed. We recommend using the latest version available.</li> <li>All files with object metadata and data are hosted and available via URLs, e.g. <code>http://data_source/study.csv</code> or file:     <code>///local_data/data_source/study.csv</code> for the case when you need to load data to ODM from a local machine on which ODM     is installed.</li> <li>Requirements for Data Loaded to ODM</li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#restrictions","title":"Restrictions","text":"<ul> <li>The script does not allow to load of several studies via one run.</li> <li>The script does not provide functionality to load data to ODM from local computer</li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#instructions","title":"Instructions","text":"<ul> <li>Open a terminal and run a command to display help</li> </ul> <pre><code>odm-import-data -h\n</code></pre> <ul> <li>Run the script with the below parameters:<ul> <li><code>-t, --token</code>: your API token  OR </li> <li><code>-at, --access-token</code>: Your Access (Bearer Token), provided by third party</li> <li><code>-H, --host, -srv, --server</code>: address of the host, e.g. https://odm.genestack.com/</li> <li><code>-s,--study</code>: URL of the study file (or -sa: accession of an existing study)</li> <li><code>-sm,--samples</code>: URL of the samples file or accession of existing samples file to be linked</li> <li><code>-lb, --libraries</code>: URL of the libraries file or accession of existing libraries file to be linked</li> <li><code>-pr, --preparations</code>: URL of hosted preparations file or accession of existing preparations file to be linked</li> <li><code>-e,--expression</code>: URL of any tabular data file (not only expression data) except Gene Variant or Flow Cytometry</li> <li><code>-em,--expression-metadata</code>: URL of any tabular metadata file (not only expression data) except Gene Variant or Flow Cytometry</li> <li><code>-v, --variant</code>: URL of the variants data file</li> <li><code>-vm, --variant-metadata</code>: URL of the variants metadata file</li> <li><code>-f, --flow-cytometry</code>: URL of the flow cytometry data file</li> <li><code>-fm, --flow-cytometry-metadata</code>: URL of the flow cytometry metadata file</li> <li><code>-tmpl, --template</code>: accession of a template to validate against, if not specified \"template marked as default\" is     used;</li> </ul> </li> </ul> <p>Additional optional parameters:</p> <ul> <li> <p>to include a gene-transcript mapping file:</p> <ul> <li><code>-mpf / mapping-file</code> - link to mapping file</li> <li><code>-mpfm / mapping-file-metadata</code> - link to metadata file for the mapping file</li> <li><code>-mpfa / mapping-file-accession</code> - accession of the existing mapping file</li> </ul> </li> <li> <p>rules for uploading mapping files are described in the section below \u201cImporting a cross-reference mapping file\u201c</p> </li> <li>to allow the loading of a duplicate of the study: the data from the links has already been previously loaded into ODM     and for testing purposes, you need to load this data again - <code>--allow-duplicates</code></li> <li>to link all entities of the study according to the data model used: data model with and without libraries and     preparations - <code>-lata, --link-all-to-all</code>. Additional rules are described in the section below \u201cLink all to all\u201c</li> <li>to enable debug mode - <code>--debug</code></li> <li>to allow the script to continue even if linking errors occurred between study     entities - <code>-ile, --ignore-linking-errors</code></li> <li>to recognize first <code>N</code> columns in expression file as feature attributes: <code>-nfa [N]</code>     or <code>--number-of-feature-attributes [N]</code></li> <li>to identify multiple measurement in expression file and use a character <code>:</code> to distinguish the     sample/library/preparation name from the measurement name in column headers: <code>-ms ':'</code>     or <code>--measurement-separator ':'</code></li> <li>to specify the uploaded data as a data class <code>C</code>: <code>-dc 'C'</code> or <code>--data-class 'C'</code><ul> <li>The following options are available: <code>Bulk transcriptomics</code>, <code>Single cell transcriptomics</code>, <code>Differential abundance (FC, pval, etc.)</code>, <code>Pathway analysis</code>, <code>Proteomics</code>, <code>Single cell proteomics</code>, <code>Metabolomics</code>, <code>Epigenomics</code>, <code>DNA methylation</code>, <code>Chemoinformatics</code>, <code>Imaging features</code>, <code>Gene panel data</code>, <code>Biomarker data</code>, <code>Physical measures</code>, <code>Blood counts</code>, <code>Other body fluid counts</code>, <code>Nanopore</code>, <code>Gene variant (VCF)</code>, <code>Flow Cytometry</code>, <code>Other</code></li> </ul> </li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#data-model","title":"Data model","text":"<p>The script supports 2 data models: </p> <ul> <li>Study - Samples - Omics data:<ul> <li>the script uses this data model if no parameters are specified for libraries or preparations loading;</li> </ul> </li> <li>Study - Samples - Libraries/Preparations - Omics data.<ul> <li>the script uses this data model if parameters for libraries or preparations loading are specified;</li> <li>omics data can be linked only to libraries or preparations;</li> <li>only expression data (the parameters --expression and --expression-metadata) is supported.</li> </ul> </li> </ul> <p>The script works sequentially, linking the object with the previous one according to the data model. Below you can find examples to demonstrate different combinations:</p>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#example-1","title":"Example 1","text":"<pre><code>odm-import-data --token [token] -H [HOST] \\\n  --study http://data_source/study.csv \\\n  --samples http://data_source/samples_1.csv \\\n  --expression http://data_source/expression_1.gct \\\n  --expression-metadata http://data_source/expression_metadata_1.gct.tsv \\\n  --expression http://data_source/expression_2.gct \\\n  --expression-metadata http://data_source/expression_metadata_2.gct.tsv\n</code></pre> <ul> <li><code>samples_1</code> will be linked to <code>study</code></li> <li><code>expression_1</code> will be linked to <code>samples_1</code></li> <li><code>expression_2</code> will be linked to <code>samples_1</code></li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#example-2","title":"Example 2","text":"<pre><code>odm-import-data --token [token] -H [HOST] \\\n  --study http://data_source/study.csv \\\n  --samples http://data_source/samples_1.csv \\\n  --libraries http://data_source/libraries_1.csv \\\n  --expression http://data_source/expression_1.gct \\\n  --expression-metadata http://data_source/expression_metadata_1.gct.tsv \\\n  --preparations http://data_source/preparations_1.csv \\\n  --expression http://data_source/expression_2.gct \\\n  --expression-metadata http://data_source/expression_metadata_2.gct.tsv\n</code></pre> <ul> <li><code>samples_1</code> will be linked to <code>study</code></li> <li><code>libraries_1</code> will be linked to <code>samples_1</code></li> <li><code>expression_1</code> will be linked to <code>libraries_1</code></li> <li><code>preparations_1</code> will be linked to <code>samples_1</code></li> <li><code>expression_2</code> will be linked to <code>preparations_1</code></li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#example-3","title":"Example 3","text":"<pre><code>odm-import-data --token [token] -H [HOST] \\\n  --study http://data_source/study.csv \\\n  --samples http://data_source/samples_1.csv \\\n  --samples http://data_source/samples_2.csv \\\n  --libraries http://data_source/libraries_1.csv \\\n  --preparations http://data_source/preparations_1.csv \\\n  --expression http://data_source/expression_1.gct \\\n  --expression-metadata http://data_source/expression_metadata_1.gct.tsv\n</code></pre> <ul> <li><code>samples_1</code> will be linked to <code>study</code></li> <li><code>samples_2</code> will be linked to <code>study</code></li> <li><code>libraries_1</code> will be linked to <code>samples_2</code></li> <li><code>preparations_1</code> will be linked to <code>samples_2</code></li> <li><code>expression_1</code> will be linked to <code>preparations_1</code></li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#link-all-to-all","title":"Link all to all","text":"<p>The <code>-lata</code> parameter allows to bypass the restriction of sequential linking of objects. The behaviour of the script with the specified <code>-lata</code> parameter depends on the used data model:</p> <ol> <li>If there are only samples in the script \u2192 the script tries to link all omics data to all samples;</li> <li>If there are libraries or preparations in the script the linking works by steps:<ul> <li>the script tries to link all libraries and all preparations to all samples;</li> <li>the script tries to link all omics data to all libraries and preparations.</li> </ul> </li> </ol>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#example-1-without-link-all-to-all","title":"Example 1 without --link-all-to-all","text":"<pre><code>odm-import-data --token [token] -H [HOST] \\\n    --study http://data_source/study.csv \\\n    --samples http://data_source/samples_1.csv \\\n    --samples http://data_source/samples_2.csv \\\n    --expression http://data_source/expression_1.gct \\\n    --expression-metadata http://data_source/expression_metadata_1.gct.tsv\n</code></pre> <ul> <li><code>samples_1</code> will be linked to <code>study</code></li> <li><code>samples_2</code> will be linked to <code>study</code></li> <li><code>expression_1</code> will be linked only to <code>samples_2</code></li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#example-2-with-link-all-to-all","title":"Example 2 with --link-all-to-all","text":"<pre><code>odm-import-data --token [token] -H [HOST] \\\n    --study http://data_source/study.csv \\\n    --samples http://data_source/samples_1.csv \\\n    --samples http://data_source/samples_2.csv \\\n    --expression http://data_source/expression_1.gct \\\n    --expression-metadata http://data_source/expression_metadata_1.gct.tsv \\\n    --link-all-to-all\n</code></pre> <ul> <li><code>samples_1</code> will be linked to <code>study</code></li> <li><code>samples_2</code> will be linked to <code>study</code></li> <li><code>expression_1</code> will be linked to <code>samples_1</code> and <code>samples_2</code></li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#example-3-with-libraries","title":"Example 3 with libraries","text":"<pre><code>odm-import-data --token [token] -H [HOST] \\\n    --study http://data_source/study.csv \\\n    --samples http://data_source/samples_1.csv \\\n    --samples http://data_source/samples_2.csv \\\n    --libraries http://data_source/libraries_1.csv \\\n    --preparations http://data_source/preparations_1.csv \\\n    --expression http://data_source/expression_1.gct \\\n    --expression-metadata http://data_source/expression_metadata_1.gct.tsv \\\n    --link-all-to-all\n</code></pre> <ul> <li><code>samples_1</code> will be linked to <code>study</code></li> <li><code>samples_2</code> will be linked to <code>study</code></li> <li><code>libraries_1</code> will be linked to <code>samples_1</code> and <code>samples_2</code></li> <li><code>preparations_1</code> will be linked to <code>samples_1</code> and <code>samples_2</code></li> <li><code>expression_1</code> will be linked to <code>preparations_1</code> and <code>libraries_1</code></li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#study-name","title":"Study name","text":"<p>By default, the Study Title field in the study metadata file will be used to set the name of the study, or if no field is present, it will be set to 'New Study'. You can rename studies via ODM GUI.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#importing-a-cross-reference-mapping-file","title":"Importing a cross-reference mapping file","text":"<p>The parameters \u201cmpf\u201d and \u201cmpfm\u201d are used to create a new mapping file with metadata and its linkage with an expression group. The parameter \u201cmpfa\u201d is used for linkage expression groups with an existing mapping file.</p> <p>How to specify the parameters:</p> <ol> <li>You can only specify both \u201cmpf\u201d and \u201cmpfm\u201d at the same time as loading expression data. Otherwise, an error will be    given: \u201cmapping file is supported with expression matrices only\u201d</li> <li>You can only specify \u201cmpfa\u201d at the same time as loading expression data. Otherwise, an error will be given: \u201cmapping    file is supported with expression matrices only\u201d</li> <li>The user can\u2019t specify \u201cmpfm\u201d without \u201cmpf\u201d. Otherwise, an error message is given: \u201cthe parameter \u201cmpf\u201d for mapping    file loading is missing\u201d</li> <li>For the sample group, you can specify either option 1 (one pair of \u201cmpfm\u201d and \u201cmpf\u201d) or option 2 (\u201cmpfa\u201d). Otherwise,    an error message is given: \"only one mapping file is expected. check the value of parameters \u201cmpf\u201d or \u201cmpfa\u201d\".</li> <li> <p>The parameters \u201cmpf\u201d, \u201cmpfm\u201d and \u201cmpfa\u201d must be after the parameters for loading expression data, for example:</p> <pre><code>odm-import-data --token [token] -H [HOST] \\\n    --study http://data_source/study.csv \\\n    --samples http://data_source/samples_1.csv \\\n    --expression http://data_source/expression_1.gct \\\n    --expression-metadata http://data_source/expression_metadata_1.gct.tsv \\\n    --expression http://data_source/expression_2.gct \\\n    --expression-metadata http://data_source/expression_metadata_2.gct.tsv \\\n    --mapping-file http://data_source/mapping.txt \\\n    --mapping-file-metadata http://data_source/mapping_metadata.tsv \\\n    --template GSF0000000 \\\n    --allow-duplicates\n</code></pre> </li> <li> <p>If <code>link-all-to-all</code> is specified the script tries to link mapping file to all expression data that was specified.</p> </li> <li>Only one mapping file can be specified along with <code>link-all-to-all</code>.</li> </ol>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#versioning","title":"Versioning","text":"<p>The script now enables users to update existing omics data files (e.g. GCT, VCF files). This is done by appending the accession of the existing data file to be updated in square brackets to the data file URL (see below). Previous versions of the data files are kept and are still available, but the active version will be set to the most recently uploaded.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#example","title":"Example","text":"<pre><code>odm-import-data --token [token] -H [HOST] \\\n    --study-accession GSF994039 \\\n    --samples GSF994040 \\\n    --expression http://exampl.com/expression.gct[GSF994565]  \\\n    --expression-metadata http://exampl.com/expression_metadata.tsv  \\\n    --variant http://exampl.com/variations.vcf[GSF994700] \\\n    --variant-metadata http://exampl.com/variant_metadata.tsv\n</code></pre> <p>As a result of the above, the data files linked to study <code>GSF994039</code> and samples <code>GSF994040</code> will be updated:</p> <ul> <li>Expression file as the next version of <code>GSF994565</code></li> <li>Variant file as the next version of <code>GSF994700</code></li> </ul> <p>Updating data file versions only works for data files linked to existing studies and samples, you cannot create a new study or new samples file at the same time as updating a data file version.</p> <p>Info</p> <p>If you get errors importing data but aren\u2019t sure why you can add the <code>--debug</code> argument to generate more detailed help information - at the end of this is the message from the server, which might tell you something about your input files.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#other-examples","title":"Other examples","text":"<p>Here you can find some predefined examples for study importing.</p>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#study-with-expressions","title":"Study with expressions","text":"<p>You can use study-samples-omics.zip archive. This archive contains:</p> <ul> <li><code>Test.study.tsv</code> \u2014 study metadata file;</li> <li><code>Test.samples.tsv</code> \u2014 samples metadata file;</li> <li><code>Test.expression.gct.tsv</code> \u2014 expression metadata file;</li> <li><code>Test.expression.gct</code> \u2014 expression data file.</li> </ul> <p>Firstly you need to upload files to data source and get links to these files. And then import a study:</p> <pre><code>odm-import-data --token [token] -H [HOST] \\\n  --study http://data_source/Test.study.tsv \\\n  --samples http://data_source/Test.samples.tsv \\\n  --expression-metadata http://data_source/Test.expression.gct.tsv \\\n  --expression http://data_source/Test.expression.gct\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#study-with-libraries-and-preparations","title":"Study with libraries and preparations","text":"<p>You can use study-samples-libraries-omics.zip archive. This archive contains:</p> <ul> <li><code>Test.study.tsv</code> \u2014 study metadata file;</li> <li><code>Test.samples.tsv</code> \u2014 samples metadata file;</li> <li><code>Test.libraries.tsv</code> \u2014 libraries metadata file;</li> <li><code>Test.preparations.tsv</code> \u2014 preparations metadata file;</li> <li><code>Test.expression.gct.tsv</code> \u2014 expression metadata file;</li> <li><code>Test.expression.gct</code> \u2014 expression data file.</li> </ul> <p>Firstly you need to upload files to data source and get links to these files. And then import a study:</p> <pre><code>odm-import-data --token [token] -H [HOST] \\\n  --study http://data_source/Test.study.tsv \\\n  --samples http://data_source/Test.samples.tsv \\\n  --libraries http://data_source/Test.libraries.tsv \\\n  --preparations http://data_source/Test.preparations.tsv \\\n  --expression-metadata http://data_source/Test.expression.gct.tsv \\\n  --expression http://data_source/Test.expression.gct\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#study-with-variants","title":"Study with variants","text":"<p>You can use study-variants.zip archive. This archive contains:</p> <ul> <li><code>Example.study.tsv</code> \u2014 study metadata file;</li> <li><code>Example.samples.tsv</code> \u2014 samples metadata file;</li> <li><code>Example.expression.gct.tsv</code> \u2014 expression metadata file;</li> <li><code>Example.expression.gct</code> \u2014 expression data file;</li> <li><code>Example.gx-dummy.tsv</code> \u2014 variants metadata file;</li> <li><code>Example.gx-dummy.vcf</code> \u2014 variants data file.</li> </ul> <p>Firstly you need to upload files to data source and get links to these files. And then import a study:</p> <pre><code>odm-import-data --token [token] -H [HOST] \\\n  --study http://data_source/Example.study.tsv \\\n  --samples http://data_source/Example.samples.tsv \\\n  --expression-metadata http://data_source/Example.expression.gct.tsv \\\n  --expression http://data_source/Example.expression.gct\n  --variant-metadata http://data_source/Example.gx-dummy.tsv\n  --variant http://data_source/Example.gx-dummy.vcf\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/study/uploading-study/#argi-study-example","title":"Argi study example","text":"<p>You can use argi-study-example.zip archive. This archive contains:</p> <ul> <li><code>arabidopsis.gct</code> \u2014 expression data file;</li> <li><code>arabidopsis_sample_metadata_uncurated.tsv</code> - samples metadata file;</li> <li><code>arabidopsis_study.tsv</code> \u2014 study metadata file.</li> </ul> <p>Firstly you need to upload files to data source and get links to these files. And then import a study:</p> <pre><code>odm-import-data --token [token] -H [HOST] \\\n  --study http://data_source/arabidopsis_study.tsv \\\n  --samples http://data_source/arabidopsis_sample_metadata_uncurated.tsv \\\n  --expression http://data_source/arabidopsis.gct\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/templates/create-or-update-template/","title":"How to load custom templates","text":"<p>This article describes how to load templates from a local computer into ODM.</p> <p>Loaded templates are available to all users on the instance.</p>"},{"location":"usage/tools/odm-sdk/terminal/templates/create-or-update-template/#requirements","title":"Requirements","text":"<ul> <li>Configured odm-sdk. See Configured odm-sdk</li> <li>The user should have the \"Set up templates\" permission and Bearer Token or API token. See Getting a Genestack API token</li> <li>A template settings json file, e.g.: default_ODM_template_settings.json</li> <li>A template json file, e.g.: Default_ODM_Template.json</li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/templates/create-or-update-template/#instructions","title":"Instructions","text":"<p>To explore the full list of supported arguments use the following command:</p> <pre><code>odm-update-template -h\n</code></pre> <ol> <li> <p>Download or create a template json file (see Requirements). Templates are collections of fields with rules determining whether the field is required, which dictionary to use (if any) etc.</p> <pre><code>[\n    {\n     \"dataType\":\"genestack:sampleObject\",\n     \"name\":\"Organism\",\n     \"metainfoType\":\"com.genestack.api.metainfo.StringValue\",\n     \"dictionaryName\":\"NCBI Taxonomy\",\n     \"isRequired\":true,\n     \"isReadOnly\":false,\n     \"description\": \"Key description, text of 500 characters\"\n    }\n]\n</code></pre> </li> <li> <p>Download the template settings json file (see Requirements)</p> </li> <li> <p>Use a text editor to edit the template settings file and change the path to match where you have put your template json file</p> <p><code>\"template_path\": \"/PATHTOTEMPLATEFILE/Default_ODM_Template.json\",</code></p> </li> <li> <p>Run the <code>odm-update-template</code> script:</p> <pre><code>odm-update-template -H GENESTACK_ENDPOINT_ADDR /PATHTOSETTINGSFILE/default_ODM_template_settings.json\n</code></pre> <p>Where <code>GENESTACK_ENDPOINT_ADDR</code> is the URL of the Genestack platform.</p> </li> </ol>"},{"location":"usage/tools/odm-sdk/terminal/templates/create-or-update-template/#template_settingsjson","title":"Template_settings.json","text":"<p>This file controls certain parameters of the template file:</p> <pre><code>{\n    \"template_path\": \"Default_ODM_Template.json\", //template path/file name\n    \"template_name\": \"Default Template\", //name of the template\n    \"replace\": true,  //if true, will replace previous template that has the same name\n    \"mark_default\": false //mark this template as the new default template for the organisation\n}\n</code></pre>"},{"location":"usage/tools/odm-sdk/terminal/templates/create-or-update-template/#how-to-create-a-new-template-using-template_schemajson","title":"How to create a new template using template_schema.json","text":"<p>The template json file is validated in ODM against an internal schema: template_schema.json</p> <ol> <li>A single template file contains the properties (keys) for the metadata of study, sample and expression objects together.</li> <li> <p>For each object type (study, samples, libraries and so on) a specific dataType should be used:</p> <p>Study: <code>dataType = \"study\"</code></p> <p>Samples: <code>dataType = \"genestack:sampleObject\"</code></p> <p>Expression (both Transcriptomics and Proteomics): <code>dataType = \"genestack:transcriptomicsParent\"</code></p> </li> <li> <p>The <code>Accession</code> property is mandatory for each type of object. The following values should be set for each dataType section:</p> <pre><code>name = \"genestack:accession\",\nmetainfoType = \"com.genestack.api.metainfo.StringValue\",\nisRequired = true,\nisReadOnly = true\n</code></pre> <p>It is recommended to include properties having <code>isRequired = true</code> into the template file. Please also check out the <code>description</code> property attribute: some properties might be required for certain functionality.</p> </li> <li> <p>The values accepted for each metadata attribute are given by the <code>metainfoType</code> key, and must be one of the following values:</p> <pre><code>\"com.genestack.api.metainfo.IntegerValue\",\n\"com.genestack.api.metainfo.DecimalValue\",\n\"com.genestack.api.metainfo.StringValue\",\n\"com.genestack.api.metainfo.BooleanValue\",\n\"com.genestack.api.metainfo.DateTimeValue\",\n\"com.genestack.api.metainfo.ExternalLink\"\n</code></pre> <ul> <li>for values like FLOAT use <code>\"com.genestack.api.metainfo.DecimalValue\"</code>;</li> <li>for values of type INT use <code>\"com.genestack.api.metainfo.IntegerValue\"</code>;</li> <li>for values of type DATE or TIME use <code>\"com.genestack.api.metainfo.DateTimeValue\"</code>.</li> </ul> <p>Please note that no value bounds can be set up currently.</p> </li> <li> <p>Dictionaries (controlled vocabularies which validate against lists of terms) can be specified for a metadata attribute using the <code>dictionaryName</code> key.    See loading new ontology.</p> </li> <li>For full details refer to the template_schema.json file.</li> <li>The order of the attributes in the template json file is preserved in the template in ODM.</li> </ol>"},{"location":"usage/tools/odm-sdk/terminal/templates/delete-template/","title":"Delete template","text":"<p>This article describes how to delete templates in ODM.</p>"},{"location":"usage/tools/odm-sdk/terminal/templates/delete-template/#requirements","title":"Requirements","text":"<ul> <li>Configured odm-sdk. See Configured odm-sdk</li> <li>The user should have the \"Manage organisation\" permission and have Bearer Token or API token. See Getting a Genestack API token</li> </ul> <p>Warning</p> <ol> <li>Currently the Default template CAN be deleted, which may cause issues, so please be careful.</li> <li>Only users with the \u201cManage organization\u201d permission can delete templates.</li> <li>The script doesn\u2019t check that the file with the provided accession actually exists so if nothing is deleted but the script runs correctly it will still output 'Success'.</li> <li>The script doesn\u2019t check the type of the file so if a study\u2019s accession is provided instead of a template\u2019s accession the study will be deleted. However, for deletion of studies please use the script from how to delete a study</li> </ol>"},{"location":"usage/tools/odm-sdk/terminal/templates/delete-template/#instructions","title":"Instructions","text":"<p>To explore the full list of supported arguments use the following command:</p> <pre><code>odm-delete-template -h\n</code></pre> <ol> <li>Before a template deletion all the studies which have this template set should be manually changed: another template which is not going to be deleted should be applied (for example, Default template). Apply template manually via the UI.</li> <li> <p>Run delete template script and follow its login instructions, replacing the host name with the name of the instance the script will apply to. The script will print \u201cSuccess\u201d or an error stacktrace in case of an error.</p> <pre><code>odm-delete-template --accession GSF244345 -H GENESTACK_ENDPOINT_ADDR\n</code></pre> <p>Where <code>GENESTACK_ENDPOINT_ADDR</code> is the URL of the Genestack platform.</p> </li> </ol>"},{"location":"usage/tools/odm-sdk/terminal/users/user-creation/","title":"Users creation","text":""},{"location":"usage/tools/odm-sdk/terminal/users/user-creation/#requirements","title":"Requirements","text":"<ul> <li>Configured odm-sdk. See Configured odm-sdk</li> <li>A users.tsv file, for example: users.tsv</li> </ul>"},{"location":"usage/tools/odm-sdk/terminal/users/user-creation/#instructions","title":"Instructions","text":"<ol> <li>Edit users.tsv file in the text editor and replace the example users with your own users - one line per user, detailing email and name, separated by a tab.</li> <li> <p>Run the script below and follow its login instructions, replacing the host name with the address of the instance the script will apply:</p> <p><code>$ odm-create-users -H localhost:8080</code> or use the -u parameter and the user alias created when setting up the odm-sdk</p> <p><code>$ odm-create-users -u your_alias</code></p> </li> <li> <p>The script will create new users and print out their passwords, for example:</p> <pre><code>  alice@alphacorp.com    uNgp4F6C    Alice\n  bob@alphacorp.com      xI3AOf2h    Bob\n</code></pre> </li> </ol>"},{"location":"usage/ui/training-materials/","title":"Training materials","text":"<ul> <li>ODM Configuration Guide</li> <li>ODM Basic Training</li> <li>ODM Advanced Training</li> </ul>"}]}